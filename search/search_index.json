{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"corpus-sc-toolkit","text":""},{"location":"#purpose","title":"Purpose","text":"<p>The library applies fields extraction and validation to Philippine statutes and decisions, uploads \"source of truth\" <code>yaml</code> file for each in R2 storage.</p>"},{"location":"#flow","title":"Flow","text":"<ol> <li>Uniform identity of objects in storage and in the database</li> </ol>"},{"location":"#technical-notes","title":"Technical Notes","text":"<ol> <li>This is a compilation of several other custom libraries, notably <code>citation-utils</code>, <code>statute-trees</code>, <code>sqlpyd</code>, <code>pylts</code>, etc.</li> <li><code>sqlpyd</code> defines an <code>TableConfig</code> which inheriting Pydantic models can use It makes creation of models / tables easier, especially for use in <code>sqlite_utils</code></li> <li>The data gathering part is tedious so it's necessary to store the model (and related source files like html) in remote file storage (<code>Cloudflare R2</code>) prior to database manipulation. The remote storage then becomes the single source of truth. Changes made to the remote file storage will need to be replicated in the database layer.</li> </ol>"},{"location":"identity/","title":"Prefix-as-Identity","text":"<p>The most important problem in converting legal-paper based constructs to digital media, to me, is the problem of identity. How do we identify (and later on) refer to documents and citations? Since we need to store information in a remote facility, using Amazon S3 / Cloudflare R2 prefix conventions seems a worthy option to consider.</p>"},{"location":"identity/#prefixed-decisions","title":"Prefixed Decisions","text":"<p>Example prefix <code>gr/118289/1999/12/13</code>, in <code>sc-decisions</code> R2 bucket, when deconstructed:</p> Key Value Description title Trans-Asia Phils. Employees Association (Tapea) And Arnel Galvez, Petitioners, Vs. National Labor Relations Commission, Trans-Asia (Phils.) And Ernesto S. De Castro, Respondents. The title of the case docket_category GR The part of the docket citation indicating the category docket_id 118289 The serial id of the docket docket_date 1999-12-13 The date found in the docket citation report_phil 378 Phil. 300 The report citation for Philippine Reports <p>When downloaded, <code>gr/118289/1999/12/13/details.yaml</code> contains fields, detected opinions.</p>"},{"location":"identity/#prefixed-statutes","title":"Prefixed Statutes","text":"<p>Another R2 bucket hosts <code>ph-statutes</code>. RA 386, as published, is <code>ra/1949/6/386/1</code> where:</p> Key Value Note title Republic Act No. 386 Represents the serialized title, in long form description An Act to Ordain and Institute the Civil Code of the Philippines Official title of the Statute category ra The statutory category in short form serialid 386 The serial id of the category variant 1 The suffix <code>/1</code> helps prevent duplicate titles (e.g. categories rule_am and rule_bm) date 1949-06-18 The year and month are included in the prefix: e.g. <code>1949/6</code> <p>The full <code>ra/1949/6/386/1/details.yaml</code> is downloadable, contain metadata including nested provisions.</p> <ol> <li>individual segments;</li> <li>an index of detected citations; and</li> <li>an index of detected statutes.</li> </ol>"},{"location":"justice/","title":"Justice","text":"<p>A Justice, as defined in this reference document, is one of many justices sitting in the Supreme Court:</p> <p>         Bases: <code>Bio</code></p>"},{"location":"justice/#corpus_sc_toolkit.decisions.justice.justice_model.Justice--justice","title":"Justice","text":"Field Type Description id int Unique identifier of the Justice based on appointment roster full_name str First + last + suffix first_name str - last_name str - suffix str e.g. Jr., Sr., III, etc. nick_name str - gender str - alias str Other names start_term str Time justice appointed end_term str Time justice chief_date str Date appointed as Chief Justice (optional) birth_date str Date of birth retire_date str Based on the Birth Date, if it exists, it is the maximum term of service allowed by law. inactive_date str Which date is earliest inactive date of the Justice, the retire date is set automatically but it is not guaranteed to to be the actual inactive date. So the inactive date is either that specified in the <code>end_term</code> or the <code>retire_date</code>, whichever is earlier. <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; # See database\n&gt;&gt;&gt; from sqlpyd import Connection\n&gt;&gt;&gt; from sqlite_utils.db import Table\n&gt;&gt;&gt; c = Connection(DatabasePath=\"test.db\")\n&gt;&gt;&gt; c.path_to_db.unlink(missing_ok=True) # tear down\n&gt;&gt;&gt; table = c.create_table(Justice)\n&gt;&gt;&gt; isinstance(table, Table)\nTrue\n&gt;&gt;&gt; # See local file\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from corpus_sc_toolkit.justice import get_justices_file\n&gt;&gt;&gt; p = Path().cwd() / \"tests\" / \"sc.yaml\" # the test file\n&gt;&gt;&gt; f = get_justices_file(p)\n&gt;&gt;&gt; f.exists()\nTrue\n&gt;&gt;&gt; # Can add all pydantic validated records from the local copy of justices to the database.\n&gt;&gt;&gt; import yaml\n&gt;&gt;&gt; res = c.add_records(Justice, yaml.safe_load(f.read_bytes()))\n&gt;&gt;&gt; len(list(table.rows))\n194\n&gt;&gt;&gt; c.path_to_db.unlink() # tear down\n</code></pre> <p>The list of justices  from the created YAML file are parsed through this model prior to being inserted into the database.</p> Source code in <code>corpus_sc_toolkit/decisions/justice/justice_model.py</code> Python<pre><code>class Justice(Bio):\n\"\"\"\n    # Justice\n    Field | Type | Description\n    --:|:--|:--\n    id |int | Unique identifier of the Justice based on appointment roster\n    full_name |str | First + last + suffix\n    first_name |str | -\n    last_name |str | -\n    suffix |str | e.g. Jr., Sr., III, etc.\n    nick_name |str | -\n    gender |str | -\n    alias |str | Other names\n    start_term |str | Time justice appointed\n    end_term |str | Time justice\n    chief_date |str | Date appointed as Chief Justice (optional)\n    birth_date |str | Date of birth\n    retire_date |str | Based on the Birth Date, if it exists, it is the maximum term of service allowed by law.\n    inactive_date |str | Which date is earliest inactive date of the Justice, the retire date is set automatically but it is not guaranteed to to be the actual inactive date. So the inactive date is either that specified in the `end_term` or the `retire_date`, whichever is earlier.\n    Examples:\n        &gt;&gt;&gt; # See database\n        &gt;&gt;&gt; from sqlpyd import Connection\n        &gt;&gt;&gt; from sqlite_utils.db import Table\n        &gt;&gt;&gt; c = Connection(DatabasePath=\"test.db\")\n        &gt;&gt;&gt; c.path_to_db.unlink(missing_ok=True) # tear down\n        &gt;&gt;&gt; table = c.create_table(Justice)\n        &gt;&gt;&gt; isinstance(table, Table)\n        True\n        &gt;&gt;&gt; # See local file\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; from corpus_sc_toolkit.justice import get_justices_file\n        &gt;&gt;&gt; p = Path().cwd() / \"tests\" / \"sc.yaml\" # the test file\n        &gt;&gt;&gt; f = get_justices_file(p)\n        &gt;&gt;&gt; f.exists()\n        True\n        &gt;&gt;&gt; # Can add all pydantic validated records from the local copy of justices to the database.\n        &gt;&gt;&gt; import yaml\n        &gt;&gt;&gt; res = c.add_records(Justice, yaml.safe_load(f.read_bytes()))\n        &gt;&gt;&gt; len(list(table.rows))\n        194\n        &gt;&gt;&gt; c.path_to_db.unlink() # tear down\n    The [list of justices ][local-file-containing-list]\n    from the created YAML file are parsed through this model prior to being inserted\n    into the database.\n    \"\"\"  # noqa: E501\n__prefix__ = \"sc\"\n__tablename__ = \"justices\"\n__indexes__ = [\n[\"last_name\", \"alias\", \"start_term\", \"inactive_date\"],\n[\"start_term\", \"inactive_date\"],\n[\"last_name\", \"alias\"],\n]\nid: int = Field(\n...,\ntitle=\"Justice ID Identifier\",\ndescription=(\n\"Starting from 1, the integer represents the order of appointment\"\n\" to the Supreme Court.\"\n),\nge=1,\nlt=1000,\ncol=int,\n)\nalias: str | None = Field(\nNone,\ntitle=\"Alias\",\ndescription=(\n\"Means of matching ponente and voting strings to the justice id.\"\n),\ncol=str,\nindex=True,\n)\nstart_term: datetime.date | None = Field(\nNone,\ntitle=\"Start Term\",\ndescription=\"Date of appointment.\",\ncol=datetime.date,\nindex=True,\n)\nend_term: datetime.date | None = Field(\nNone,\ntitle=\"End Term\",\ndescription=\"Date of termination.\",\ncol=datetime.date,\nindex=True,\n)\nchief_date: datetime.date | None = Field(\nNone,\ntitle=\"Date Appointed As Chief Justice\",\ndescription=(\n\"When appointed, the extension title of the justice changes from\"\n\" 'J.' to 'C.J'. for cases that are decided after the date of\"\n\" appointment but before the date of retirement.\"\n),\ncol=datetime.date,\nindex=True,\n)\nbirth_date: datetime.date | None = Field(\nNone,\ntitle=\"Date of Birth\",\ndescription=(\n\"The Birth Date is used to determine the retirement age of the\"\n\" justice. Under the 1987 constitution, this is\"\nf\" {MAX_JUSTICE_AGE}. There are missing dates: see Jose Generoso\"\n\" 41, Grant Trent 14, Fisher 19, Moir 20.\"\n),\ncol=datetime.date,\nindex=True,\n)\nretire_date: datetime.date | None = Field(\nNone,\ntitle=\"Mandatory Retirement Date\",\ndescription=(\n\"Based on the Birth Date, if it exists, it is the maximum term of\"\n\" service allowed by law.\"\n),\ncol=datetime.date,\nindex=True,\n)\ninactive_date: datetime.date | None = Field(\nNone,\ntitle=\"Date\",\ndescription=(\n\"Which date is earliest inactive date of the Justice, the retire\"\n\" date is set automatically but it is not guaranteed to to be the\"\n\" actual inactive date. So the inactive date is either that\"\n\" specified in the `end_term` or the `retire_date`, whichever is\"\n\" earlier.\"\n),\ncol=datetime.date,\nindex=True,\n)\n@validator(\"retire_date\")\ndef retire_date_70_years(cls, v, values):\nif v and values[\"birth_date\"]:\nif values[\"birth_date\"] + rd(years=MAX_JUSTICE_AGE) != v:\nraise ValueError(\"Must be 70 years from birth date.\")\nreturn v\nclass Config:\nuse_enum_values = True\n@classmethod\ndef from_data(cls, data: dict):\ndef extract_date(text: str | None) -&gt; datetime.date | None:\nreturn parse(text).date() if text else None\nbio = Bio.from_dict(data)\n# Not all have aliases; default needed\nalias = data.pop(\"Alias\", None)\nif not alias:\nif bio.last_name and bio.suffix:\nalias = f\"{bio.last_name} {bio.suffix}\".lower()\nretire_date = None\nif dob := extract_date(data.pop(\"Born\")):\nretire_date = dob + rd(years=MAX_JUSTICE_AGE)\n# Assume that the retire_date is latest possible date of inactivity\n# but if end_date is present, use this instead\ninactive_date = retire_date\nif end_date := extract_date(data.pop(\"End of term\")):\ninactive_date = end_date or retire_date\nreturn cls(\n**bio.dict(exclude_none=True),\nid=data.pop(\"#\"),\nalias=alias,\nbirth_date=dob,\nstart_term=extract_date(data.pop(\"Start of term\")),\nend_term=end_date,\nchief_date=extract_date(data.pop(\"Appointed chief\")),\nretire_date=retire_date,\ninactive_date=inactive_date,\n)\n@classmethod\ndef view_chiefs(cls, c: Connection) -&gt; list[dict]:\n\"\"\"Get general information of the chief justices and their\n        dates of appointment.\"\"\"\nview = \"chief_dates\"\nif view in c.db.view_names():\nreturn list(c.db[view].rows)\nc.db.create_view(\nview,\nsql=sqlenv.get_template(\"decisions/chief_dates.sql\").render(\njustice_table=Justice.__tablename__\n),\n)\nreturn list(c.db[view].rows)\n</code></pre>"},{"location":"justice/#corpus_sc_toolkit.decisions.justice.justice_model.Justice-functions","title":"Functions","text":""},{"location":"justice/#corpus_sc_toolkit.decisions.justice.justice_model.Justice.view_chiefs","title":"<code>view_chiefs(c)</code>  <code>classmethod</code>","text":"<p>Get general information of the chief justices and their dates of appointment.</p> Source code in <code>corpus_sc_toolkit/decisions/justice/justice_model.py</code> Python<pre><code>@classmethod\ndef view_chiefs(cls, c: Connection) -&gt; list[dict]:\n\"\"\"Get general information of the chief justices and their\n    dates of appointment.\"\"\"\nview = \"chief_dates\"\nif view in c.db.view_names():\nreturn list(c.db[view].rows)\nc.db.create_view(\nview,\nsql=sqlenv.get_template(\"decisions/chief_dates.sql\").render(\njustice_table=Justice.__tablename__\n),\n)\nreturn list(c.db[view].rows)\n</code></pre>"},{"location":"justice/#source-list-from-api","title":"Source list from API","text":"<p>Need <code>GH_TOKEN</code> to copy from /corpus/justices/sc.yaml to iterator of dicts.</p> <p>Yields:</p> Type Description <code>Iterator[dict]</code> <p>Iterator[dict]: Justices from API</p> Source code in <code>corpus_sc_toolkit/decisions/justice/justice_list.py</code> Python<pre><code>def get_justices_from_api() -&gt; Iterator[dict]:\n\"\"\"Need `GH_TOKEN` to copy from /corpus/justices/sc.yaml to iterator of dicts.\n    Yields:\n        Iterator[dict]: Justices from API\n    \"\"\"\nlogger.debug(\"Extracting justice list from API.\")\nres = gh.get(\n\"https://api.github.com/repos/justmars/corpus/contents/justices/sc.yaml\"\n)\nif res.status_code == HTTPStatus.OK:\nyield from yaml.safe_load(res.content)\nraise Exception(f\"No justice list, see {res=}\")\n</code></pre>"},{"location":"justice/#local-file-containing-list","title":"Local file containing list","text":"<p>Return, if existing, the path to the <code>local_file</code> (*.yaml) containing a list of validated Justices; if it doesn't exist yet, create it by calling get_justices_from_api().</p> <p>Parameters:</p> Name Type Description Default <code>local_file</code> <code>Path</code> <p>Path to justice list. See default folder /\"sc.yaml\"</p> <code>Path(__file__).parent / 'sc.yaml'</code> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; p = Path().cwd() / \"justice\" / \"sc.yaml\" # the test file\n&gt;&gt;&gt; f = get_justices_file(p)\n&gt;&gt;&gt; f.exists()\nTrue\n</code></pre> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Yaml file containing list of justices</p> Source code in <code>corpus_sc_toolkit/decisions/justice/justice_list.py</code> Python<pre><code>def get_justices_file(\nlocal_file: Path = Path(__file__).parent / \"sc.yaml\",\n) -&gt; Path:\n\"\"\"Return, if existing, the path to the `local_file` (*.yaml) containing\n    a list of validated [Justices][justice]; if it doesn't exist yet, create it by\n    calling [get_justices_from_api()][source-list-from-api].\n    Args:\n        local_file (Path, optional): Path to justice list. See default folder /\"sc.yaml\"\n    Examples:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; p = Path().cwd() / \"justice\" / \"sc.yaml\" # the test file\n        &gt;&gt;&gt; f = get_justices_file(p)\n        &gt;&gt;&gt; f.exists()\n        True\n    Returns:\n        Path: Yaml file containing list of justices\n    \"\"\"\nif local_file.exists():\nlogger.debug(\"Local justice list file used.\")\nreturn local_file\nwith open(local_file, \"w+\") as writefile:\nyaml.safe_dump(\ndata=[\nJustice.from_data(justice_data).dict(exclude_none=True)\nfor justice_data in get_justices_from_api()\n],\nstream=writefile,\nsort_keys=False,\ndefault_flow_style=False,\n)\nreturn local_file\n</code></pre>"},{"location":"justice/#cleaning-raw-justice-names","title":"Cleaning Raw Justice Names","text":"<p>         Bases: <code>NamedTuple</code></p> Source code in <code>corpus_sc_toolkit/decisions/justice/justice_name.py</code> Python<pre><code>class OpinionWriterName(NamedTuple):\nwriter: str | None = None\nper_curiam: bool = False\n@classmethod\ndef extract(cls, text: str | None):\nif not text:\nreturn None\nif text:\nif IS_PER_CURIAM.search(text):\nreturn cls(per_curiam=True)\nreturn cls(writer=cls.clean(text))\n@classmethod\ndef clean(cls, text: str) -&gt; str | None:\n\"\"\"Each `ponente` name stored in `decisions_tbl` of the database has been\n        made uniform, e.g.:\n        Examples:\n            &gt;&gt;&gt; OpinionWriterName.clean(\"REYES , J.B.L, Acting C.J.\") # sample name 1\n            'reyes, j.b.l.'\n            &gt;&gt;&gt; OpinionWriterName.clean(\"REYES, J, B. L. J.\") # sample name 2\n            'reyes, j.b.l.'\n        \"\"\"\nno_asterisk = re.sub(r\"\\[?(\\*)+\\]?\", \"\", text)\nsurname = init_surnames(no_asterisk)\nno_suffix = TitleSuffixClean.clean_end(surname).strip()\nrepl = CommonTypos.replace_value(no_suffix).strip()\nres = repl + \".\" if repl.endswith((\" jr\", \" sr\")) else repl\nreturn res if 4 &lt; len(res) &lt; 20 else None\n</code></pre>"},{"location":"justice/#corpus_sc_toolkit.decisions.justice.justice_name.OpinionWriterName-functions","title":"Functions","text":""},{"location":"justice/#corpus_sc_toolkit.decisions.justice.justice_name.OpinionWriterName.clean","title":"<code>clean(text)</code>  <code>classmethod</code>","text":"<p>Each <code>ponente</code> name stored in <code>decisions_tbl</code> of the database has been made uniform, e.g.:</p> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; OpinionWriterName.clean(\"REYES , J.B.L, Acting C.J.\") # sample name 1\n'reyes, j.b.l.'\n&gt;&gt;&gt; OpinionWriterName.clean(\"REYES, J, B. L. J.\") # sample name 2\n'reyes, j.b.l.'\n</code></pre> Source code in <code>corpus_sc_toolkit/decisions/justice/justice_name.py</code> Python<pre><code>@classmethod\ndef clean(cls, text: str) -&gt; str | None:\n\"\"\"Each `ponente` name stored in `decisions_tbl` of the database has been\n    made uniform, e.g.:\n    Examples:\n        &gt;&gt;&gt; OpinionWriterName.clean(\"REYES , J.B.L, Acting C.J.\") # sample name 1\n        'reyes, j.b.l.'\n        &gt;&gt;&gt; OpinionWriterName.clean(\"REYES, J, B. L. J.\") # sample name 2\n        'reyes, j.b.l.'\n    \"\"\"\nno_asterisk = re.sub(r\"\\[?(\\*)+\\]?\", \"\", text)\nsurname = init_surnames(no_asterisk)\nno_suffix = TitleSuffixClean.clean_end(surname).strip()\nrepl = CommonTypos.replace_value(no_suffix).strip()\nres = repl + \".\" if repl.endswith((\" jr\", \" sr\")) else repl\nreturn res if 4 &lt; len(res) &lt; 20 else None\n</code></pre>"},{"location":"notes/","title":"Notes","text":"Python<pre><code>&gt;&gt;&gt; from corpus_base.helpers import most_popular\n&gt;&gt;&gt; [i for i in most_popular(c, db)] # excluding per curiams and unidentified cases\n[\n('1994-07-04', '2017-08-09', 'mendoza', 1297), # note multiple personalities named mendoza, hence long range from 1994-2017\n('1921-10-22', '1992-07-03', 'paras', 1287), # note multiple personalities named paras, hence long range from 1921-1992\n('2009-03-17', '2021-03-24', 'peralta', 1243),\n('1998-06-18', '2009-10-30', 'quisumbing', 1187),\n('1999-06-28', '2011-06-02', 'ynares-santiago', 1184),\n('1956-04-28', '2008-04-04', 'panganiban', 1102),\n('1936-11-19', '2009-11-05', 'concepcion', 1058), # note multiple personalities named concepcion, hence long range from 1936-2009\n('1954-07-30', '1972-08-18', 'reyes, j.b.l.', 1053),\n('1903-11-21', '1932-03-31', 'johnson', 1043),\n('1950-11-16', '1999-05-23', 'bautista angelo', 1028), # this looks like bad data\n('2001-11-20', '2019-10-15', 'carpio', 1011),\n...\n]\n</code></pre>"},{"location":"notes/#view-chief-justice-dates","title":"View chief justice dates","text":"Python<pre><code>&gt;&gt;&gt; from corpus_base import Justice\n&gt;&gt;&gt; Justice.view_chiefs(c)\n[\n{\n'id': 178,\n'last_name': 'Gesmundo',\n'chief_date': '2021-04-05',\n'max_end_chief_date': None,\n'actual_inactive_as_chief': None,\n'years_as_chief': None\n},\n{\n'id': 162,\n'last_name': 'Peralta',\n'chief_date': '2019-10-23',\n'max_end_chief_date': '2021-04-04',\n'actual_inactive_as_chief': '2021-03-27',\n'years_as_chief': 2\n},\n{\n'id': 163,\n'last_name': 'Bersamin',\n'chief_date': '2018-11-26',\n'max_end_chief_date': '2019-10-22',\n'actual_inactive_as_chief': '2019-10-18',\n'years_as_chief': 1\n},\n{\n'id': 160,\n'last_name': 'Leonardo-De Castro',\n'chief_date': '2018-08-28',\n'max_end_chief_date': '2018-11-25',\n'actual_inactive_as_chief': '2018-10-08',\n'years_as_chief': 0\n}...\n]\n</code></pre>"},{"location":"statutes/","title":"Statutes","text":""},{"location":"statutes/#statute-extraction","title":"Statute Extraction","text":"<p>The statute-trees and statute-patterns libraries are help fashion content into nested provisions. These are also used in determining whether an decision's opinion contains references to a statute.</p>"},{"location":"decisions/components/","title":"Components","text":"<pre><code>flowchart TB\ndecision---a(list of opinions)\na---mm(each opinion has its own metadata)\nmm---writer(justice id)\nmm---title(title of opinion)\nmm---substructures(each opinion can consist of)\nsubstructures---segments(subdivided text)\nsubstructures---citations(a citation index)\nsubstructures---statutes(a statute index)\ntitle--op(ponencia)\ntitle--xconcur\ntitle--xdissent\ntitle--xseparate</code></pre>"},{"location":"decisions/components/#decision-opinions","title":"Decision Opinions","text":"<p>Each decision is divided into opinions:</p> <p>         Bases: <code>BaseModel</code></p> <p>A decision may contain a single opinion entitled the Ponencia or span multiple opinions depending on the justices of the Court who are charged to decide a specific case.</p> Source code in <code>corpus_sc_toolkit/decisions/decision_opinions.py</code> Python<pre><code>class DecisionOpinion(BaseModel):\n\"\"\"A decision may contain a single opinion entitled the Ponencia or span\n    multiple opinions depending on the justices of the Court who are charged to decide\n    a specific case.\n    \"\"\"\nid: str = Field(..., title=\"Opinion ID\", col=str)\ndecision_id: str  # later replaced in decision.py\njustice_id: int | None = None\npdf: str | None = Field(\ndefault=None,\ntitle=\"PDF URL\",\ndescription=\"Links to downloadable PDF, if it exists\",\ncol=str,\n)\ntitle: str | None = Field(\n...,\ndescription=\"How opinion called, e.g. Ponencia, Concurring Opinion,\",\ncol=str,\n)\ntags: list[OpinionTag] | None = Field(\ndefault=None,\ndescription=\"e.g. main, dissenting, concurring, separate\",\n)\nremark: str | None = Field(\ndefault=None,\ntitle=\"Short Remark on Opinion\",\ndescription=\"e.g. 'I reserve my right, etc.', 'On leave.', etc.\",\ncol=str,\nfts=True,\n)\nconcurs: list[dict] | None = Field(default=None)\ntext: str = Field(\n...,\ndescription=\"Text proper of opinion (ideally in markdown)\",\ncol=str,\nfts=True,\n)\nstatutes: list[MentionedStatute]\nsegments: list[OpinionSegment]\ncitations: list[Citation]\nclass Config:\nuse_enum_values = True\ndef make_filename_for_upload(self, file_ext: str = \"md\"):\nif file_ext not in (\"md\", \"txt\"):\nlogger.error(\"Improper file upload extension.\")\nreturn None\nif self.title == \"Ponencia\":\nreturn f\"ponencia.{file_ext}\"\nelif self.justice_id:\nreturn f\"{self.justice_id}.{file_ext}\"\nlogger.warning(f\"No filename for {self.id=} {self.decision_id=}\")\nreturn None\ndef to_storage(self, decision_prefix: str, file_ext: str = \"md\"):\nif file_ext not in (\"md\", \"txt\"):\nlogger.error(\"Improper file upload extension.\")\nreturn None\nlogger.debug(f\"Uploading opinion {self.id=}\")\nprefix_title = self.make_filename_for_upload(file_ext)\nif not prefix_title:\nlogger.warning(\"Missing title, skip upload.\")\nreturn None\ntemp_md = Path(__file__).parent / \"_tmp\" / f\"temp_op.{file_ext}\"\ntemp_md.write_text(self.text)\ndecision_storage.upload(\nfile_like=temp_md,\nloc=f\"{decision_prefix}/opinions/{prefix_title}\",\nargs=decision_storage.set_extra_meta(self.storage_meta),\n)\ntemp_md.unlink(missing_ok=True)\n@property\ndef storage_meta(self):\nif not self.title or not self.justice_id:\nreturn {}\nreturn {\n\"id\": self.id,\n\"title\": self.title,\n\"tags\": \",\".join([t for t in self.tags]) if self.tags else None,\n\"justice_id\": self.justice_id,\n\"pdf\": self.pdf,\n\"text_length\": len(self.text),\n\"num_unique_statutes\": len(self.statutes),\n\"num_detected_citations\": len(self.citations),\n\"num_counted_segments\": len(self.segments),\n}\n@classmethod\ndef get_headline(cls, text: str) -&gt; str | None:\n\"\"\"Markdown contains H1 header, extract this header.\"\"\"\nif match := OPINION_MD_H1.search(text):\nlabel = match.group(\"label\")\nif len(label) &gt;= 5 and len(label) &lt;= 50:\nreturn label\nelse:\nlogger.error(f\"Improper opinion {label=} regex capture.\")\nreturn None\n@classmethod\ndef key_from_md_prefix(cls, prefix: str) -&gt; str | None:\n\"\"\"Given a prefix containing a filename, e.g. `/hello/test/ponencia.md`,\n        get the identifying key of the filename, e.g. `ponencia`.\"\"\"\nif \"/\" in prefix and prefix.endswith(\".md\"):\nreturn prefix.split(\"/\")[-1].split(\".\")[0]\nreturn None\n@classmethod\ndef make_opinion(\ncls,\npath: str,\ndecision_id: str,\njustice_id: int | None,\ntext: str,\n):\n\"\"\"Common opinion instantiator for both `cls.from_folder()` and\n        `cls.from_storage()`\n        The `path` field implies that this may be a ponencia / opinion field.\n        Ponencias are labeled 'ponencia.md' while Opinions are labeled\n        '&lt;digit&gt;.md' where the digit refers to the justice id (representing\n        the Justice) that penned the opinion.\n        The `justice_id` refers to upstream value previously acquired for\n        the ponencia. If the path's key refers to 'ponencia', then this\n        `justice_id` value is utilized as the writer id; otherwise, use\n        the &lt;digit&gt;.\n        Each opinion consists of `segments`, `citations`, and `statutes`.\n        \"\"\"\nkey = cls.key_from_md_prefix(path)\nif not key:\nlogger.error(f\"No key from {path=}\")\nreturn None\ntitle = cls.get_headline(text)\nif not title:\nlogger.error(f\"No headline from {path=}; means no title.\")\nreturn None\njustice_id = justice_id if key == \"ponencia\" else int(key)\nopinion_id = f\"{decision_id}-{key}\"\nreturn cls(\nid=opinion_id,\ndecision_id=decision_id,\ntitle=title,\ntext=text,\njustice_id=justice_id,\ntags=OpinionTag.detect(title),\ncitations=list(Citation.extract_citations(text=text)),\nstatutes=list(MentionedStatute.set_counted_statute(text=text)),\nsegments=list(\nOpinionSegment.make_segments(\ndecision_id=decision_id,\nopinion_id=opinion_id,\ntext=text,\n)\n),\n)\n@classmethod\ndef from_folder(\ncls,\nopinions_folder: Path,\ndecision_id: str,\nponente_id: int | None = None,\n):\n\"\"\"Assumes local folder containing opinions in .md format.\n        The `ponente_id`, if present, will be used to populate the ponencia\n        opinion.\"\"\"\nfor opinion_path in opinions_folder.glob(\"**/*.md\"):\nif opinion := cls.make_opinion(\npath=str(opinion_path),\ndecision_id=decision_id,\njustice_id=ponente_id,\ntext=opinion_path.read_text(),\n):\nyield opinion\n</code></pre>"},{"location":"decisions/components/#corpus_sc_toolkit.decisions.decision_opinions.DecisionOpinion-functions","title":"Functions","text":""},{"location":"decisions/components/#corpus_sc_toolkit.decisions.decision_opinions.DecisionOpinion.from_folder","title":"<code>from_folder(opinions_folder, decision_id, ponente_id=None)</code>  <code>classmethod</code>","text":"<p>Assumes local folder containing opinions in .md format. The <code>ponente_id</code>, if present, will be used to populate the ponencia opinion.</p> Source code in <code>corpus_sc_toolkit/decisions/decision_opinions.py</code> Python<pre><code>@classmethod\ndef from_folder(\ncls,\nopinions_folder: Path,\ndecision_id: str,\nponente_id: int | None = None,\n):\n\"\"\"Assumes local folder containing opinions in .md format.\n    The `ponente_id`, if present, will be used to populate the ponencia\n    opinion.\"\"\"\nfor opinion_path in opinions_folder.glob(\"**/*.md\"):\nif opinion := cls.make_opinion(\npath=str(opinion_path),\ndecision_id=decision_id,\njustice_id=ponente_id,\ntext=opinion_path.read_text(),\n):\nyield opinion\n</code></pre>"},{"location":"decisions/components/#corpus_sc_toolkit.decisions.decision_opinions.DecisionOpinion.get_headline","title":"<code>get_headline(text)</code>  <code>classmethod</code>","text":"<p>Markdown contains H1 header, extract this header.</p> Source code in <code>corpus_sc_toolkit/decisions/decision_opinions.py</code> Python<pre><code>@classmethod\ndef get_headline(cls, text: str) -&gt; str | None:\n\"\"\"Markdown contains H1 header, extract this header.\"\"\"\nif match := OPINION_MD_H1.search(text):\nlabel = match.group(\"label\")\nif len(label) &gt;= 5 and len(label) &lt;= 50:\nreturn label\nelse:\nlogger.error(f\"Improper opinion {label=} regex capture.\")\nreturn None\n</code></pre>"},{"location":"decisions/components/#corpus_sc_toolkit.decisions.decision_opinions.DecisionOpinion.key_from_md_prefix","title":"<code>key_from_md_prefix(prefix)</code>  <code>classmethod</code>","text":"<p>Given a prefix containing a filename, e.g. <code>/hello/test/ponencia.md</code>, get the identifying key of the filename, e.g. <code>ponencia</code>.</p> Source code in <code>corpus_sc_toolkit/decisions/decision_opinions.py</code> Python<pre><code>@classmethod\ndef key_from_md_prefix(cls, prefix: str) -&gt; str | None:\n\"\"\"Given a prefix containing a filename, e.g. `/hello/test/ponencia.md`,\n    get the identifying key of the filename, e.g. `ponencia`.\"\"\"\nif \"/\" in prefix and prefix.endswith(\".md\"):\nreturn prefix.split(\"/\")[-1].split(\".\")[0]\nreturn None\n</code></pre>"},{"location":"decisions/components/#corpus_sc_toolkit.decisions.decision_opinions.DecisionOpinion.make_opinion","title":"<code>make_opinion(path, decision_id, justice_id, text)</code>  <code>classmethod</code>","text":"<p>Common opinion instantiator for both <code>cls.from_folder()</code> and <code>cls.from_storage()</code></p> <p>The <code>path</code> field implies that this may be a ponencia / opinion field. Ponencias are labeled 'ponencia.md' while Opinions are labeled '.md' where the digit refers to the justice id (representing the Justice) that penned the opinion. <p>The <code>justice_id</code> refers to upstream value previously acquired for the ponencia. If the path's key refers to 'ponencia', then this <code>justice_id</code> value is utilized as the writer id; otherwise, use the . <p>Each opinion consists of <code>segments</code>, <code>citations</code>, and <code>statutes</code>.</p> Source code in <code>corpus_sc_toolkit/decisions/decision_opinions.py</code> Python<pre><code>@classmethod\ndef make_opinion(\ncls,\npath: str,\ndecision_id: str,\njustice_id: int | None,\ntext: str,\n):\n\"\"\"Common opinion instantiator for both `cls.from_folder()` and\n    `cls.from_storage()`\n    The `path` field implies that this may be a ponencia / opinion field.\n    Ponencias are labeled 'ponencia.md' while Opinions are labeled\n    '&lt;digit&gt;.md' where the digit refers to the justice id (representing\n    the Justice) that penned the opinion.\n    The `justice_id` refers to upstream value previously acquired for\n    the ponencia. If the path's key refers to 'ponencia', then this\n    `justice_id` value is utilized as the writer id; otherwise, use\n    the &lt;digit&gt;.\n    Each opinion consists of `segments`, `citations`, and `statutes`.\n    \"\"\"\nkey = cls.key_from_md_prefix(path)\nif not key:\nlogger.error(f\"No key from {path=}\")\nreturn None\ntitle = cls.get_headline(text)\nif not title:\nlogger.error(f\"No headline from {path=}; means no title.\")\nreturn None\njustice_id = justice_id if key == \"ponencia\" else int(key)\nopinion_id = f\"{decision_id}-{key}\"\nreturn cls(\nid=opinion_id,\ndecision_id=decision_id,\ntitle=title,\ntext=text,\njustice_id=justice_id,\ntags=OpinionTag.detect(title),\ncitations=list(Citation.extract_citations(text=text)),\nstatutes=list(MentionedStatute.set_counted_statute(text=text)),\nsegments=list(\nOpinionSegment.make_segments(\ndecision_id=decision_id,\nopinion_id=opinion_id,\ntext=text,\n)\n),\n)\n</code></pre>"},{"location":"decisions/components/#opinion-segments","title":"Opinion Segments","text":"<p>Each decision is divided into opinions:</p> <p>         Bases: <code>BaseModel</code></p> <p>A decision is naturally subdivided into [opinions][decision opinions]. Breaking down opinions into segments is an attempt to narrow down the scope of decisions to smaller portions for purposes of FTS search snippets and analysis.</p> Source code in <code>corpus_sc_toolkit/decisions/decision_opinion_segments.py</code> Python<pre><code>class OpinionSegment(BaseModel):\n\"\"\"A decision is naturally subdivided into [opinions][decision opinions].\n    Breaking down opinions into segments is an attempt to narrow down the scope\n    of decisions to smaller portions for purposes of FTS search snippets and analysis.\n    \"\"\"\nid: str = Field(..., col=str)\nopinion_id: str  # later replaced in decisions.py\ndecision_id: str  # later replaced in decisions.py\nposition: str = Field(\ndefault=...,\ntitle=\"Relative Position\",\ndescription=\"Line number of text stripped from source.\",\ncol=int,\nindex=True,\n)\nchar_count: int = Field(\ndefault=...,\ntitle=\"Character Count\",\ndescription=\"Makes it easier to discover patterns.\",\ncol=int,\nindex=True,\n)\nsegment: str = Field(\ndefault=...,\ntitle=\"Body Segment\",\ndescription=\"Partial fragment of opinion.\",\ncol=str,\nfts=True,\n)\n@classmethod\ndef segmentize(\ncls, full_text: str, min_num_chars: int = 10\n) -&gt; Iterator[dict]:\n\"\"\"Split first by double-spaced breaks `\\\\n\\\\n` and then by\n        single spaced breaks `\\\\n` to get the position of the segment.\n        Will exclude footnotes and segments with less than 10 characters.\n        Args:\n            full_text (str): The opinion to segment\n        Yields:\n            Iterator[dict]: The partial segment data fields\n        \"\"\"\nif cleaned_text := standardize(full_text):\nif subdivisions := double_spaced.split(cleaned_text):\nfor idx, text in enumerate(subdivisions):\nif lines := single_spaced.split(text):\nfor sub_idx, segment in enumerate(lines):\n# --- marks the footnote boundary in # converter.py\nif segment == \"---\":\nreturn\nposition = f\"{idx}-{sub_idx}\"\nchar_count = len(segment)\nif char_count &gt; min_num_chars:\nyield {\n\"position\": position,\n\"segment\": segment,\n\"char_count\": char_count,\n}\n@classmethod\ndef make_segments(\ncls, decision_id: str, opinion_id: str, text: str\n) -&gt; Iterator[Self]:\n\"\"\"Auto-generated segments based on the text of the opinion.\"\"\"\nfor extract in cls.segmentize(text):\nyield cls(\nid=f\"{opinion_id}-{extract['position']}\",\ndecision_id=decision_id,\nopinion_id=opinion_id,\n**extract,\n)\n</code></pre>"},{"location":"decisions/components/#corpus_sc_toolkit.decisions.decision_opinion_segments.OpinionSegment-functions","title":"Functions","text":""},{"location":"decisions/components/#corpus_sc_toolkit.decisions.decision_opinion_segments.OpinionSegment.make_segments","title":"<code>make_segments(decision_id, opinion_id, text)</code>  <code>classmethod</code>","text":"<p>Auto-generated segments based on the text of the opinion.</p> Source code in <code>corpus_sc_toolkit/decisions/decision_opinion_segments.py</code> Python<pre><code>@classmethod\ndef make_segments(\ncls, decision_id: str, opinion_id: str, text: str\n) -&gt; Iterator[Self]:\n\"\"\"Auto-generated segments based on the text of the opinion.\"\"\"\nfor extract in cls.segmentize(text):\nyield cls(\nid=f\"{opinion_id}-{extract['position']}\",\ndecision_id=decision_id,\nopinion_id=opinion_id,\n**extract,\n)\n</code></pre>"},{"location":"decisions/components/#corpus_sc_toolkit.decisions.decision_opinion_segments.OpinionSegment.segmentize","title":"<code>segmentize(full_text, min_num_chars=10)</code>  <code>classmethod</code>","text":"<p>Split first by double-spaced breaks <code>\\n\\n</code> and then by single spaced breaks <code>\\n</code> to get the position of the segment.</p> <p>Will exclude footnotes and segments with less than 10 characters.</p> <p>Parameters:</p> Name Type Description Default <code>full_text</code> <code>str</code> <p>The opinion to segment</p> required <p>Yields:</p> Type Description <code>Iterator[dict]</code> <p>Iterator[dict]: The partial segment data fields</p> Source code in <code>corpus_sc_toolkit/decisions/decision_opinion_segments.py</code> Python<pre><code>@classmethod\ndef segmentize(\ncls, full_text: str, min_num_chars: int = 10\n) -&gt; Iterator[dict]:\n\"\"\"Split first by double-spaced breaks `\\\\n\\\\n` and then by\n    single spaced breaks `\\\\n` to get the position of the segment.\n    Will exclude footnotes and segments with less than 10 characters.\n    Args:\n        full_text (str): The opinion to segment\n    Yields:\n        Iterator[dict]: The partial segment data fields\n    \"\"\"\nif cleaned_text := standardize(full_text):\nif subdivisions := double_spaced.split(cleaned_text):\nfor idx, text in enumerate(subdivisions):\nif lines := single_spaced.split(text):\nfor sub_idx, segment in enumerate(lines):\n# --- marks the footnote boundary in # converter.py\nif segment == \"---\":\nreturn\nposition = f\"{idx}-{sub_idx}\"\nchar_count = len(segment)\nif char_count &gt; min_num_chars:\nyield {\n\"position\": position,\n\"segment\": segment,\n\"char_count\": char_count,\n}\n</code></pre>"},{"location":"decisions/fields/","title":"Decision Fields","text":"<pre><code>flowchart TB\ndf(decision fields)\ndf---format(general format)\nformat---html\nformat---pdf\ndf---dx(case title)\ndf---composition(court composition)\ncomposition---eb(en banc: 15 justices)\ncomposition---division(division: 5 justices)\ndf---cite(citation)\ndf---date(date promulgated)</code></pre> <p>         Bases: <code>BaseModel</code></p> Field Type Description id str Using the docket citation as identifier, uses <code>.</code> as dividing mechanism prefix str Location in cloud storage for saving / retrieving content delimited by <code>/</code> origin str Where decision was sourced from title str The case title, this can be classified into tags description str The citation display date datetime.date The date the case was promulgated date_scraped datetime.date The date the case was scraped citation optional[Citation] The citation object composition CourtComposition Whether the court sat en banc or in division category DecisionCategory Whether the case decided was a decision or a resolution raw_ponente optional[str] Who decided case, if available justice_id optional[int] The justice id, if available per_curiam bool. Defaults to False. Whether case was decided per curiam is_pdf bool. Defaults to False. Whether case originated from a PDF file fallo optional[str] Detected fallo / dispositive portion voting optional[str] Detected voting line emails list[str] Emails of authors opinions list[DecisionOpinion] [Opinion structures][decision opinions] which can be further [subdivided into segments][opinion segments] Source code in <code>corpus_sc_toolkit/decisions/decision_fields.py</code> Python<pre><code>class DecisionFields(BaseModel):\n\"\"\"\n    Field | Type | Description\n    :--:|:--:|:--\n    id | str | Using the docket citation as identifier, uses `.` as dividing mechanism\n    prefix | str | Location in cloud storage for saving / retrieving content delimited by `/`\n    origin | str | Where decision was sourced from\n    title | str | The case title, this can be classified into [tags][title-tags]\n    description | str | The citation display\n    date | datetime.date | The date the case was promulgated\n    date_scraped | datetime.date | The date the case was scraped\n    citation | optional[Citation] | The citation object\n    composition | [CourtComposition][court-composition] | Whether the court sat en banc or in division\n    category | [DecisionCategory][decision-category] | Whether the case decided was a decision or a resolution\n    raw_ponente| optional[str] | Who decided case, if available\n    justice_id | optional[int] | The [justice id][justice], if available\n    per_curiam | bool. Defaults to False. | Whether case was decided per curiam\n    is_pdf | bool. Defaults to False. | Whether case originated from a PDF file\n    fallo | optional[str] | Detected fallo / dispositive portion\n    voting | optional[str] | Detected [voting line][vote-lines]\n    emails | list[str] | Emails of authors\n    opinions | list[DecisionOpinion] | [Opinion structures][decision opinions] which can be further [subdivided into segments][opinion segments]\n    \"\"\"  # noqa: E501\nid: str = Field(col=str)\nprefix: str = Field(col=str)\ncitation: Citation | None = Field(default=None)  # overriden in decision.py\norigin: str = Field(col=str, index=True)\ntitle: str = Field(col=str, index=True, fts=True)\ndescription: str = Field(col=str, index=True, fts=True)\ndate: datetime.date = Field(col=datetime.date, index=True)\ndate_scraped: datetime.date = Field(col=datetime.date, index=True)\ncomposition: CourtComposition = Field(default=None, col=str, index=True)\ncategory: DecisionCategory = Field(default=None, col=str, index=True)\nraw_ponente: str | None = Field(\ndefault=None,\ntitle=\"Ponente\",\ndescription=\"Lowercase and be suitable for matching a justice id.\",\ncol=str,\nindex=True,\n)\njustice_id: int | None = Field(\ndefault=None,\ntitle=\"Justice ID\",\ndescription=\"Get justice_id using `update_justice_ids.sql`.\",\ncol=int,\nindex=True,\n)\nper_curiam: bool = Field(\ndefault=False,\ntitle=\"Is Per Curiam\",\ndescription=\"If true, decision was penned anonymously.\",\ncol=bool,\nindex=True,\n)\nis_pdf: bool | None = Field(default=False, col=bool, index=True)\nfallo: str | None = Field(default=None, col=str, index=True, fts=True)\nvoting: str | None = Field(default=None, col=str, index=True, fts=True)\nemails: list[str] = Field(default_factory=list)\nopinions: list[DecisionOpinion] = Field(default_factory=list)\n@root_validator()\ndef citation_date_is_object_date(cls, values):\ncite, date = values.get(\"citation\"), values.get(\"date\")\nif cite and cite.docket_date:\nif cite.docket_date != date:\nmsg = f\"Inconsistent {cite.docket_date=} vs. {date=};\"\nlogger.error(msg)\nraise ValueError(msg)\nreturn values\nclass Config:\nuse_enum_values = True\n@property\ndef storage_meta(self):\n\"\"\"Metadata included as extra arguments to file uploaded.\"\"\"\nif not self.citation or not self.citation.storage_prefix:\nreturn {}\nreturn {\n\"id\": self.id,\n\"prefix\": self.prefix,\n\"title\": self.title,\n\"category\": self.category,\n\"composition\": self.composition,\n\"docket_category\": self.citation.docket_category,\n\"docket_id\": self.citation.docket_serial,\n\"docket_date\": self.date.isoformat(),\n\"report_phil\": self.citation.phil,\n\"report_scra\": self.citation.scra,\n\"report_off_gaz\": self.citation.offg,\n\"has_pdf\": self.is_pdf,\n}\n@classmethod\ndef key_raw(cls, dated_prefix: str) -&gt; str | None:\n\"\"\"Is suffix `details.yaml` present in result of `cls.iter_dockets()`?\"\"\"\nkey = f\"{dated_prefix}/details.yaml\"\ntry:\nDECISION_CLIENT.get_object(Bucket=DECISION_BUCKET_NAME, Key=key)\nreturn key\nexcept Exception:\nreturn None\n@classmethod\ndef key_pdf(cls, dated_prefix: str) -&gt; str | None:\n\"\"\"Is suffix `pdf.yaml` present in result of `cls.iter_dockets()`?\"\"\"\nkey = f\"{dated_prefix}/pdf.yaml\"\ntry:\nDECISION_CLIENT.get_object(Bucket=DECISION_BUCKET_NAME, Key=key)\nreturn key\nexcept Exception:\nreturn None\ndef put_in_storage(self, suffix: str):\n\"\"\"Puts Pydantic exported data dict to `details.yaml` or `pdf.yaml` in\n        R2, depending on the value of `suffix`.\"\"\"\nif suffix not in (\"details.yaml\", \"pdf.yaml\"):\nraise Exception(\"Invalid upload path.\")\noutput_data = self.dict(exclude_none=True)\nremote_loc = f\"{self.prefix}/{suffix}\"\ntemp_file = decision_storage.make_temp_yaml_path_from_data(output_data)\nargs = decision_storage.set_extra_meta(self.storage_meta)\nlogger.info(f\"Uploading file to {remote_loc=}\")\ndecision_storage.upload(file_like=temp_file, loc=remote_loc, args=args)\ntemp_file.unlink()\n@classmethod\ndef get_from_storage(cls, prefix: str) -&gt; Self:\n\"\"\"Retrieves Pydantic exported data dict from either `details.yaml`, `pdf.yaml`\n        in R2 (see extracted prefix from `key_pdf()` or `key_raw`()`) and instantiate\n        the dict as a class instance.\"\"\"\nif not prefix.endswith((\"details.yaml\", \"pdf.yaml\")):\nraise Exception(\"Bad path for DecisionFields base class.\")\ndata = decision_storage.restore_temp_yaml(prefix)\nif not data:\nraise Exception(f\"Could not originate {prefix=}\")\nlogger.info(f\"Retrieved file from {prefix=}\")\nreturn cls(**data)\n</code></pre>"},{"location":"decisions/fields/#corpus_sc_toolkit.decisions.decision_fields.DecisionFields-attributes","title":"Attributes","text":""},{"location":"decisions/fields/#corpus_sc_toolkit.decisions.decision_fields.DecisionFields.storage_meta","title":"<code>storage_meta</code>  <code>property</code>","text":"<p>Metadata included as extra arguments to file uploaded.</p>"},{"location":"decisions/fields/#corpus_sc_toolkit.decisions.decision_fields.DecisionFields-functions","title":"Functions","text":""},{"location":"decisions/fields/#corpus_sc_toolkit.decisions.decision_fields.DecisionFields.get_from_storage","title":"<code>get_from_storage(prefix)</code>  <code>classmethod</code>","text":"<p>Retrieves Pydantic exported data dict from either <code>details.yaml</code>, <code>pdf.yaml</code> in R2 (see extracted prefix from <code>key_pdf()</code> or <code>key_raw</code>()`) and instantiate the dict as a class instance.</p> Source code in <code>corpus_sc_toolkit/decisions/decision_fields.py</code> Python<pre><code>@classmethod\ndef get_from_storage(cls, prefix: str) -&gt; Self:\n\"\"\"Retrieves Pydantic exported data dict from either `details.yaml`, `pdf.yaml`\n    in R2 (see extracted prefix from `key_pdf()` or `key_raw`()`) and instantiate\n    the dict as a class instance.\"\"\"\nif not prefix.endswith((\"details.yaml\", \"pdf.yaml\")):\nraise Exception(\"Bad path for DecisionFields base class.\")\ndata = decision_storage.restore_temp_yaml(prefix)\nif not data:\nraise Exception(f\"Could not originate {prefix=}\")\nlogger.info(f\"Retrieved file from {prefix=}\")\nreturn cls(**data)\n</code></pre>"},{"location":"decisions/fields/#corpus_sc_toolkit.decisions.decision_fields.DecisionFields.key_pdf","title":"<code>key_pdf(dated_prefix)</code>  <code>classmethod</code>","text":"<p>Is suffix <code>pdf.yaml</code> present in result of <code>cls.iter_dockets()</code>?</p> Source code in <code>corpus_sc_toolkit/decisions/decision_fields.py</code> Python<pre><code>@classmethod\ndef key_pdf(cls, dated_prefix: str) -&gt; str | None:\n\"\"\"Is suffix `pdf.yaml` present in result of `cls.iter_dockets()`?\"\"\"\nkey = f\"{dated_prefix}/pdf.yaml\"\ntry:\nDECISION_CLIENT.get_object(Bucket=DECISION_BUCKET_NAME, Key=key)\nreturn key\nexcept Exception:\nreturn None\n</code></pre>"},{"location":"decisions/fields/#corpus_sc_toolkit.decisions.decision_fields.DecisionFields.key_raw","title":"<code>key_raw(dated_prefix)</code>  <code>classmethod</code>","text":"<p>Is suffix <code>details.yaml</code> present in result of <code>cls.iter_dockets()</code>?</p> Source code in <code>corpus_sc_toolkit/decisions/decision_fields.py</code> Python<pre><code>@classmethod\ndef key_raw(cls, dated_prefix: str) -&gt; str | None:\n\"\"\"Is suffix `details.yaml` present in result of `cls.iter_dockets()`?\"\"\"\nkey = f\"{dated_prefix}/details.yaml\"\ntry:\nDECISION_CLIENT.get_object(Bucket=DECISION_BUCKET_NAME, Key=key)\nreturn key\nexcept Exception:\nreturn None\n</code></pre>"},{"location":"decisions/fields/#corpus_sc_toolkit.decisions.decision_fields.DecisionFields.put_in_storage","title":"<code>put_in_storage(suffix)</code>","text":"<p>Puts Pydantic exported data dict to <code>details.yaml</code> or <code>pdf.yaml</code> in R2, depending on the value of <code>suffix</code>.</p> Source code in <code>corpus_sc_toolkit/decisions/decision_fields.py</code> Python<pre><code>def put_in_storage(self, suffix: str):\n\"\"\"Puts Pydantic exported data dict to `details.yaml` or `pdf.yaml` in\n    R2, depending on the value of `suffix`.\"\"\"\nif suffix not in (\"details.yaml\", \"pdf.yaml\"):\nraise Exception(\"Invalid upload path.\")\noutput_data = self.dict(exclude_none=True)\nremote_loc = f\"{self.prefix}/{suffix}\"\ntemp_file = decision_storage.make_temp_yaml_path_from_data(output_data)\nargs = decision_storage.set_extra_meta(self.storage_meta)\nlogger.info(f\"Uploading file to {remote_loc=}\")\ndecision_storage.upload(file_like=temp_file, loc=remote_loc, args=args)\ntemp_file.unlink()\n</code></pre>"},{"location":"decisions/fields/#source-of-decisions","title":"Source of Decisions","text":""},{"location":"decisions/fields/#pdf-files-from-the-supreme-court-official-website","title":"PDF Files from the Supreme Court Official Website","text":"<p>A pre-existing sqlite database, found in <code>s3://corpus-pdf/db</code>, contains justices and decisions extracted from pdf files. The database is replicated via the process below:</p> Python<pre><code>&gt;&gt;&gt; from dotenv import find_dotenv, load_dotenv\n&gt;&gt;&gt; from pylts import ConfigS3\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from sqlpyd import Connection\n&gt;&gt;&gt; load_dotenv(find_dotenv()) # ensure presence of env variables for litestream\n&gt;&gt;&gt; stream = ConfigS3(s3='s3://corpus-pdf/db', folder=Path().cwd() / \"data\")\n&gt;&gt;&gt; # stream.restore() # will download the database\n&gt;&gt;&gt; c = Connection(DatabasePath=str(stream.dbpath), WAL=True) # database access via `c.db`\n</code></pre> <p>Since the pdf files from the database have not yet been replicated to R2 storage, we need to initialize its contents into  an <code>DecisionPDF</code> where we can</p> Python<pre><code>&gt;&gt;&gt; from corpus_sc_toolkit import DecisionPDF\n&gt;&gt;&gt; interim_objs = DecisionPDF.originate(c.db) # raw data found in the database\n&gt;&gt;&gt; x = next(interim_objs) # x is an instance of an Interim Decision\n&gt;&gt;&gt; prefix_and_path = x.dump() # creates a temporary file with a conventional prefix\n&gt;&gt;&gt; prefix_and_path # display results\n('GR/2021/10/227403/pdf.yaml',\nPosixPath('&lt;path-to-library&gt;/corpus_sc_toolkit/_tmp/temp.yaml'))\n&gt;&gt;&gt; x.put_in_storage(prefix_and_path) # uploads files, including opinions as txt files.\n</code></pre>"},{"location":"decisions/fields/#html-files-from-the-supreme-court-e-library-website-other-sources","title":"HTML Files from the Supreme Court e-Library Website, other sources","text":"<p>The Supreme Court website contains decisions starting from 1996 onwards. Decisions dated prior to that year are only available through various secondary sources.</p> Python<pre><code>&gt;&gt;&gt; from corpus_sc_toolkit import DecisionHTML\n&gt;&gt;&gt; prefix = \"GR/2021/10/227403/details.yaml\" # assuming this exists\n&gt;&gt;&gt; obj = DecisionHTML.get(prefix)\n&gt;&gt;&gt; obj = type(obj) # x is an instance of a DecisionHTML\n</code></pre>"},{"location":"decisions/fields/#metadata","title":"Metadata","text":""},{"location":"decisions/fields/#decision-source","title":"Decision Source","text":"<p>         Bases: <code>str</code>, <code>Enum</code></p> <p>The Supreme Court website contains decisions starting from 1996 onwards. Decisions dated prior to that year are only available through various secondary sources.</p> <p>For purposes of classification and determining their provenance, we will use the following categorization:</p> source description sc 1996 onwards from the Supreme Court legacy Prior to 1996, from other sources Source code in <code>corpus_sc_toolkit/decisions/fields/source.py</code> Python<pre><code>class DecisionSource(str, Enum):\n\"\"\"The Supreme Court website contains decisions starting from 1996 onwards.\n    Decisions dated prior to that year are only available through various secondary\n    sources.\n    For purposes of classification and determining their provenance, we will use the\n    following categorization:\n    source | description\n    --:|:--\n    sc | 1996 onwards from the Supreme Court\n    legacy | Prior to 1996, from other sources\n    \"\"\"\nsc = \"sc\"\nlegacy = \"legacy\"\n@classmethod\ndef from_date(cls, d: datetime.date):\nif d &gt;= datetime.datetime(year=1996, month=1, day=1):\nreturn DecisionSource.sc\nreturn DecisionSource.legacy\n</code></pre>"},{"location":"decisions/fields/#decision-category","title":"Decision Category","text":"<p>         Bases: <code>str</code>, <code>Enum</code></p> <p>Each Decision (which is not classified as a 'notice of a minute resolution') is categorized as being either a <code>Decision</code> or a <code>Resolution</code>.</p> <p>A minute resolution, as described by the internal rules of the Philippine Supreme Court, is characterized as follows:</p> <p>A notice of a minute resolution shall be embodied in a  letter of the Clerk of Court or the Division Clerk of Court notifying the parties of the action or actions taken in their case. In the absence of or whenever so deputized by the Clerk of Court or the Division Clerk of Court, the Assistant Clerk of Court or Assistant Division Clerk of Court may likewise sign the letter which shall be in the following form:</p> <p>x x x</p> <p>Sirs/Mesdames:</p> <p>NOTICE</p> <p>Please take notice that the Court ... x x x</p> Source code in <code>corpus_sc_toolkit/decisions/fields/category.py</code> Python<pre><code>class DecisionCategory(str, Enum):\n\"\"\"Each Decision (which is not classified as a 'notice of a minute resolution')\n    is categorized as being either a `Decision` or a `Resolution`.\n    A minute resolution, as described by the internal rules of the Philippine\n    Supreme Court, is characterized as follows:\n    &gt; A notice of a minute resolution shall be embodied in a  letter of the Clerk\n    of Court or the Division Clerk of Court notifying the parties of the action or\n    actions taken in their case. In the absence of or whenever so deputized by the\n    Clerk of Court or the Division Clerk of Court, the Assistant Clerk of Court or\n    Assistant Division Clerk of Court may likewise sign the letter which shall\n    be in the following form:\n    &gt; x x x\n    &gt; Sirs/Mesdames:\n    &gt; NOTICE\n    &gt; Please take notice that the Court ... x x x\n    \"\"\"\ndecision = \"Decision\"\nresolution = \"Resolution\"\nminute = \"Minute Resolution\"\nother = \"Unspecified\"\n@classmethod\ndef _setter(cls, text: str | None):\n\"\"\"Detect pattern based on simple matching of characters.\n        Examples:\n            &gt;&gt;&gt; text = \"R E S O L U T I O N\"\n            &gt;&gt;&gt; DecisionCategory._setter(text)\n            &lt;DecisionCategory.resolution: 'Resolution'&gt;\n            &gt;&gt;&gt; text2 = \"Decission\" # wrongly spelled\n            &gt;&gt;&gt; DecisionCategory._setter(text2)\n            &lt;DecisionCategory.decision: 'Decision'&gt;\n        \"\"\"\nif text:\nif CATEGORY_START_DECISION.search(text):\nreturn cls.decision\nelif CATEGORY_START_RESOLUTION.search(text):\nreturn cls.resolution\nreturn cls.other\n@classmethod\ndef set_category(cls, category: str | None = None, notice: int | None = 0):\nif notice:\nreturn cls.minute\nif category:\ncls._setter(category)\nreturn cls.other\n</code></pre>"},{"location":"decisions/fields/#court-composition","title":"Court Composition","text":"<p>         Bases: <code>str</code>, <code>Enum</code></p> <p>The Supreme Court may sit either <code>en banc</code> (the full 15 member complement) or by <code>division</code> (5-member groups).</p> Source code in <code>corpus_sc_toolkit/decisions/fields/composition.py</code> Python<pre><code>class CourtComposition(str, Enum):\n\"\"\"The Supreme Court may sit either `en banc` (the full 15 member complement)\n    or by `division` (5-member groups).\n    \"\"\"\nenbanc = \"En Banc\"\ndivision = \"Division\"\nother = \"Unspecified\"\n@classmethod\ndef _setter(cls, text: str | None):\n\"\"\"Detect pattern based on simple matching of characters.\n        Examples:\n            &gt;&gt;&gt; text = \"En Banc\"\n            &gt;&gt;&gt; CourtComposition._setter(text)\n            &lt;CourtComposition.enbanc: 'En Banc'&gt;\n            &gt;&gt;&gt; text2 = \"Special First Division\"\n            &gt;&gt;&gt; CourtComposition._setter(text2)\n            &lt;CourtComposition.division: 'Division'&gt;\n        \"\"\"\nif text:\nif \"banc\".casefold() in text.casefold():\nreturn cls.enbanc\nelif \"div\".casefold() in text.casefold():\nreturn cls.division\nreturn cls.other\n</code></pre>"},{"location":"decisions/fields/#title-tags","title":"Title Tags","text":"<p>The title of a decision is indicative of its classification. This is a sample algorithm to determine tags associated with the title.</p> <p>Parameters:</p> Name Type Description Default <code>decision_pk</code> <code>str</code> <p>The decision id</p> required <code>text</code> <code>str</code> <p>The title text</p> required <p>Yields:</p> Type Description <code>Iterator[dict[str, str]]</code> <p>Iterator[dict[str, str]]: The different tags associated based on the text.</p> Source code in <code>corpus_sc_toolkit/decisions/fields/tags.py</code> Python<pre><code>def tags_from_title(decision_pk: str, text: str) -&gt; Iterator[dict[str, str]]:\n\"\"\"The title of a decision is indicative of its classification. This is a\n    sample algorithm to determine tags associated with the title.\n    Args:\n        decision_pk (str): The decision id\n        text (str): The title text\n    Yields:\n        Iterator[dict[str, str]]: The different tags associated based on the text.\n    \"\"\"\ndef is_contained(target_text: str, matches: list[str]) -&gt; bool:\nreturn any(m.lower() in target_text.lower() for m in matches)\ntags = []\nif is_contained(\ntext,\n[\n\"habeas corpus\",\n\"guardianship of\",\n\"writ of amparo\",\n\"habeas data\",\n\"change of name\",\n\"correction of entries\",\n\"escheat\",\n],\n):\ntags.append(\"Special Proceeding\")\nif is_contained(\ntext,\n[\n\"matter of the will\",\n\"testamentary proceedings\",\n\"probate\",\n],\n):\ntags.append(\"Succession\")\nif is_contained(\ntext,\n[\n\"disbarment\",\n\"practice of law\",\n\"office of the court administrator\",\n\"disciplinary action against atty.\",\n],\n):\ntags.append(\"Legal Ethics\")\nif is_contained(\ntext,\n[\n\"for naturalization\",\n\"certificate of naturalization\",\n\"petition for naturalization\",\n\"citizen of the philippines\",\n\"commissioner of immigration\",\n\"commissioners of immigration\",\n\"philippine citizenship\",\n],\n):\ntags.append(\"Immigration\")\nif is_contained(\ntext,\n[\n\"central bank of the philippines\",\n\"bangko sentral ng pilipinas\",\n],\n):\ntags.append(\"Banking\")\nif is_contained(\ntext,\n[\n\"el pueblo de filipinas\",\n\"el pueblo de las islas filipinas\",\n\"los estados unidos\",\n\"testamentaria\",\n],\n):\ntags.append(\"Spanish\")\nif is_contained(\ntext,\n[\"the united States, plaintiff \"],\n):\ntags.append(\"United States\")\nif is_contained(\ntext,\n[\n\"people of the philipppines\",\n\"people of the philippines\",\n\"people  of the philippines\",\n\"people of the  philippines\",\n\"people of the philipines\",\n\"people of the philippine islands\",\n\"people philippines, of the\",\n\"sandiganbayan\",\n\"tanodbayan\",\n\"ombudsman\",\n],\n):\ntags.append(\"Crime\")\nif is_contained(\ntext,\n[\n\"director of lands\",\n\"land registration\",\n\"register of deeds\",\n],\n):\ntags.append(\"Property\")\nif is_contained(\ntext,\n[\n\"agrarian reform\",\n\"darab\",\n],\n):\ntags.append(\"Agrarian Reform\")\nif is_contained(\ntext,\n[\n\"collector of internal revenue\",\n\"commissioner of internal revenue\",\n\"bureau of internal revenue\",\n\"court of tax appeals\",\n],\n):\ntags.append(\"Taxation\")\nif is_contained(\ntext,\n[\n\"collector of customs\",\n\"commissioner of customs\",\n],\n):\ntags.append(\"Customs\")\nif is_contained(\ntext,\n[\n\"commission on elections\",\n\"comelec\",\n\"electoral tribunal\",\n],\n):\ntags.append(\"Elections\")\nif is_contained(\ntext,\n[\n\"workmen's compensation commission\",\n\"employees' compensation commission\",\n\"national labor relations commission\",\n\"bureau of labor relations\",\n\"nlrc\",\n\"labor union\",\n\"court of industrial relations\",\n],\n):\ntags.append(\"Labor\")\nfor tag in tags:\nyield {\"decision_id\": decision_pk, \"tag\": tag}\n</code></pre>"},{"location":"decisions/fields/#vote-lines","title":"Vote Lines","text":""},{"location":"decisions/fields/#clean","title":"Clean","text":"<p>Various steps to remove non-essential text from the voteline found.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | None</code> <p>The voteline.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: The cleaned voteline, if found.</p> Source code in <code>corpus_sc_toolkit/decisions/fields/voteline.py</code> Python<pre><code>def voteline_clean(text: str | None) -&gt; str | None:\n\"\"\"Various steps to remove non-essential text from the voteline found.\n    Args:\n        text (str | None): The voteline.\n    Returns:\n        str | None: The cleaned voteline, if found.\n    \"\"\"\nif not text:\nreturn None\ntext = text.lstrip(\". \").rstrip()\ninit = markdownify(text).replace(\"*\", \"\").strip()\nif len(text) &lt; VOTEFULL_MIN_LENGTH:\nreturn None\nclean = WHITELIST.sub(\"\", init)\nadd_concur_line = clean.replace(\"concur.\", \"concur.\\n\")\nunchair = CHAIRPERSON.sub(\"\", add_concur_line)\nrelined = multilines.sub(\"\\n\", unchair)\nstartings = startlines.sub(\"\", relined)\nendings = endlines.sub(\"\", startings)\nreturn endings.strip()\n</code></pre>"},{"location":"decisions/fields/#validate","title":"Validate","text":"<p>Checks if certain criteria would qualify the line as a voteline.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Candidate text.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the text can be considered a voteline.</p> Source code in <code>corpus_sc_toolkit/decisions/fields/voteline.py</code> Python<pre><code>def is_line_ok(text: str) -&gt; bool:\n\"\"\"Checks if certain criteria would qualify the line as a voteline.\n    Args:\n        text (str): Candidate text.\n    Returns:\n        bool: Whether the text can be considered a voteline.\n    \"\"\"\nhas_proper_length = VOTELINE_MAX_LENGTH &gt; len(text) &gt; VOTELINE_MIN_LENGTH\nhas_indicator = re.search(r\"(C\\.|J\\.)?J\\.\", text)\nnot_all_caps = not text.isupper()\nfirst_char_capital_letter = re.search(r\"^[A-Z]\", text)\nreturn all(\n[\nhas_proper_length,\nhas_indicator,\nnot_all_caps,\nfirst_char_capital_letter,\n]\n)\n</code></pre>"},{"location":"decisions/fields/#extract","title":"Extract","text":"<p>Applicable to content found in the elibrary, this refers to a line under the decision / resolution which consolidates the votes of each member of the Court.</p> <p>Parameters:</p> Name Type Description Default <code>decision_pk</code> <code>str</code> <p>The decision id</p> required <code>text</code> <code>str</code> <p>The title text</p> required <p>Yields:</p> Type Description <code>Iterator[dict[str, str]]</code> <p>Iterator[dict[str, str]]: The voting lines associated with the decision id.</p> Source code in <code>corpus_sc_toolkit/decisions/fields/voteline.py</code> Python<pre><code>def extract_votelines(decision_pk: str, text: str) -&gt; Iterator[dict[str, str]]:\n\"\"\"Applicable to content found in the elibrary, this refers to a line\n    under the decision / resolution which consolidates the votes of each\n    member of the Court.\n    Args:\n        decision_pk (str): The decision id\n        text (str): The title text\n    Yields:\n        Iterator[dict[str, str]]: The voting lines associated with the decision id.\n    \"\"\"\nfor line in text.splitlines():\nif is_line_ok(line):\nyield dict(decision_id=decision_pk, text=line)\n</code></pre>"}]}