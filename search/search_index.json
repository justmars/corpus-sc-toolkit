{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"corpus-sc-toolkit","text":"<p>Toolkit to process component elements of a Philippine Supreme Court decision.</p> <ol> <li>Justice Identification</li> <li>Meta Components of a Decision</li> <li>Loading Decisions from Local Path</li> <li>Loading Decisions from PDF-Based DB</li> </ol>"},{"location":"justice/","title":"Justice","text":""},{"location":"justice/#source-list-from-api","title":"Source list from API","text":"<p>A master list of Justices is found in the github <code>/corpus</code> repository. Provided a <code>GH_TOKEN</code> is declared as an environment variable, this will pull that list into an iterator of dicts.</p> <p>Yields:</p> Type Description <code>Iterator[dict]</code> <p>Iterator[dict]: Justices from the API</p> Source code in <code>corpus_sc_toolkit/justice/justice_list.py</code> Python<pre><code>def get_justices_from_api() -&gt; Iterator[dict]:\n\"\"\"A master list of [Justices][justice] is found in the github `/corpus` repository.\n    Provided a `GH_TOKEN` is declared as an environment variable,\n    this will pull that list into an iterator of dicts.\n    Yields:\n        Iterator[dict]: Justices from the API\n    \"\"\"\nlogger.debug(\"Extracting justice list from API.\")\nwith httpx.Client() as client:\nres = client.get(\nurl=GITHUB_JUSTICES_URL,\nheaders=GITHUB_HEADERS,\ntimeout=120,\n)\nif res.status_code == HTTPStatus.OK:\nyield from yaml.safe_load(res.content)\nreturn\nraise Exception(f\"Could not get justice list, see {res=}\")\n</code></pre>"},{"location":"justice/#local-file-containing-list","title":"Local file containing list","text":"<p>Return, if existing, the path to the <code>local_file</code> (*.yaml) containing a list of validated Justices; if it doesn't exist yet, create it by calling get_justices_from_api().</p> <p>Parameters:</p> Name Type Description Default <code>local_file</code> <code>Path</code> <p>description. Defaults to JUSTICE_LOCAL.</p> <code>JUSTICE_LOCAL</code> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; p = Path().cwd() / \"tests\" / \"sc.yaml\" # the test file\n&gt;&gt;&gt; f = get_justices_file(p)\n&gt;&gt;&gt; f.exists()\nTrue\n</code></pre> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Yaml file containing list of justices</p> Source code in <code>corpus_sc_toolkit/justice/justice_list.py</code> Python<pre><code>def get_justices_file(local_file: Path = JUSTICE_LOCAL) -&gt; Path:\n\"\"\"Return, if existing, the path to the `local_file` (*.yaml) containing\n    a list of validated [Justices][justice]; if it doesn't exist yet, create it by\n    calling [get_justices_from_api()][source-list-from-api].\n    Args:\n        local_file (Path, optional): _description_. Defaults to JUSTICE_LOCAL.\n    Examples:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; p = Path().cwd() / \"tests\" / \"sc.yaml\" # the test file\n        &gt;&gt;&gt; f = get_justices_file(p)\n        &gt;&gt;&gt; f.exists()\n        True\n    Returns:\n        Path: Yaml file containing list of justices\n    \"\"\"\nif local_file.exists():\nlogger.debug(\"Local justice list file used.\")\nreturn local_file\nwith open(local_file, \"w+\") as writefile:\nyaml.safe_dump(\ndata=[\nJustice.from_data(justice_data).dict(exclude_none=True)\nfor justice_data in get_justices_from_api()\n],\nstream=writefile,\nsort_keys=False,\ndefault_flow_style=False,\n)\nreturn local_file\n</code></pre>"},{"location":"justice/#justice-model-instance","title":"Justice model instance","text":"<p>         Bases: <code>Bio</code></p>"},{"location":"justice/#corpus_sc_toolkit.justice.justice_model.Justice--justice","title":"Justice","text":"<p>Based on sqlpyd <code>TableConfig</code>, the declaration of the model makes it easier to create a table based on a given list of Pydantic fields. The list of justices  from the created YAML file are parsed through this model prior to being inserted into the database.</p> Field Type Description id int Unique identifier of the Justice full_name str First + last + suffix first_name str - last_name str - suffix str e.g. Jr., Sr., III, etc. nick_name str - gender str - alias str Other names start_term str Time justice appointed end_term str Time justice chief_date str Date appointed as Chief Justice (optional) birth_date str Date of birth retire_date str Based on the Birth Date, if it exists, it is the maximum term of service allowed by law. inactive_date str Which date is earliest inactive date of the Justice, the retire date is set automatically but it is not guaranteed to to be the actual inactive date. So the inactive date is either that specified in the <code>end_term</code> or the <code>retire_date</code>, whichever is earlier. <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; # See database\n&gt;&gt;&gt; from sqlpyd import Connection\n&gt;&gt;&gt; from sqlite_utils.db import Table\n&gt;&gt;&gt; c = Connection(DatabasePath=\"test.db\")\n&gt;&gt;&gt; c.path_to_db.unlink(missing_ok=True) # tear down\n&gt;&gt;&gt; table = c.create_table(Justice)\n&gt;&gt;&gt; isinstance(table, Table)\nTrue\n&gt;&gt;&gt; # See local file\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from corpus_sc_toolkit.justice import get_justices_file\n&gt;&gt;&gt; p = Path().cwd() / \"tests\" / \"sc.yaml\" # the test file\n&gt;&gt;&gt; f = get_justices_file(p)\n&gt;&gt;&gt; f.exists()\nTrue\n&gt;&gt;&gt; # Can add all pydantic validated records from the local copy of justices to the database.\n&gt;&gt;&gt; import yaml\n&gt;&gt;&gt; res = c.add_records(Justice, yaml.safe_load(f.read_bytes()))\n&gt;&gt;&gt; len(list(table.rows))\n194\n&gt;&gt;&gt; c.path_to_db.unlink() # tear down\n</code></pre> Source code in <code>corpus_sc_toolkit/justice/justice_model.py</code> Python<pre><code>class Justice(Bio):\n\"\"\"\n    # Justice\n    Based on sqlpyd `TableConfig`, the declaration of the model makes it easier\n    to create a table based on a given list of Pydantic fields. The [list of justices ][local-file-containing-list]\n    from the created YAML file are parsed through this model prior to being inserted\n    into the database.\n    Field | Type | Description\n    --:|:--|:--\n    id |int | Unique identifier of the Justice\n    full_name |str | First + last + suffix\n    first_name |str | -\n    last_name |str | -\n    suffix |str | e.g. Jr., Sr., III, etc.\n    nick_name |str | -\n    gender |str | -\n    alias |str | Other names\n    start_term |str | Time justice appointed\n    end_term |str | Time justice\n    chief_date |str | Date appointed as Chief Justice (optional)\n    birth_date |str | Date of birth\n    retire_date |str | Based on the Birth Date, if it exists, it is the maximum term of service allowed by law.\n    inactive_date |str | Which date is earliest inactive date of the Justice, the retire date is set automatically but it is not guaranteed to to be the actual inactive date. So the inactive date is either that specified in the `end_term` or the `retire_date`, whichever is earlier.\n    Examples:\n        &gt;&gt;&gt; # See database\n        &gt;&gt;&gt; from sqlpyd import Connection\n        &gt;&gt;&gt; from sqlite_utils.db import Table\n        &gt;&gt;&gt; c = Connection(DatabasePath=\"test.db\")\n        &gt;&gt;&gt; c.path_to_db.unlink(missing_ok=True) # tear down\n        &gt;&gt;&gt; table = c.create_table(Justice)\n        &gt;&gt;&gt; isinstance(table, Table)\n        True\n        &gt;&gt;&gt; # See local file\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; from corpus_sc_toolkit.justice import get_justices_file\n        &gt;&gt;&gt; p = Path().cwd() / \"tests\" / \"sc.yaml\" # the test file\n        &gt;&gt;&gt; f = get_justices_file(p)\n        &gt;&gt;&gt; f.exists()\n        True\n        &gt;&gt;&gt; # Can add all pydantic validated records from the local copy of justices to the database.\n        &gt;&gt;&gt; import yaml\n        &gt;&gt;&gt; res = c.add_records(Justice, yaml.safe_load(f.read_bytes()))\n        &gt;&gt;&gt; len(list(table.rows))\n        194\n        &gt;&gt;&gt; c.path_to_db.unlink() # tear down\n    \"\"\"  # noqa: E501\n__prefix__ = \"sc\"\n__tablename__ = \"justices\"\n__indexes__ = [\n[\"last_name\", \"alias\", \"start_term\", \"inactive_date\"],\n[\"start_term\", \"inactive_date\"],\n[\"last_name\", \"alias\"],\n]\nid: int = Field(\n...,\ntitle=\"Justice ID Identifier\",\ndescription=(\n\"Starting from 1, the integer represents the order of appointment\"\n\" to the Supreme Court.\"\n),\nge=1,\nlt=1000,\ncol=int,\n)\nalias: str | None = Field(\nNone,\ntitle=\"Alias\",\ndescription=(\n\"Means of matching ponente and voting strings to the justice id.\"\n),\ncol=str,\nindex=True,\n)\nstart_term: datetime.date | None = Field(\nNone,\ntitle=\"Start Term\",\ndescription=\"Date of appointment.\",\ncol=datetime.date,\nindex=True,\n)\nend_term: datetime.date | None = Field(\nNone,\ntitle=\"End Term\",\ndescription=\"Date of termination.\",\ncol=datetime.date,\nindex=True,\n)\nchief_date: datetime.date | None = Field(\nNone,\ntitle=\"Date Appointed As Chief Justice\",\ndescription=(\n\"When appointed, the extension title of the justice changes from\"\n\" 'J.' to 'C.J'. for cases that are decided after the date of\"\n\" appointment but before the date of retirement.\"\n),\ncol=datetime.date,\nindex=True,\n)\nbirth_date: datetime.date | None = Field(\nNone,\ntitle=\"Date of Birth\",\ndescription=(\n\"The Birth Date is used to determine the retirement age of the\"\n\" justice. Under the 1987 constitution, this is\"\nf\" {MAX_JUSTICE_AGE}. There are missing dates: see Jose Generoso\"\n\" 41, Grant Trent 14, Fisher 19, Moir 20.\"\n),\ncol=datetime.date,\nindex=True,\n)\nretire_date: datetime.date | None = Field(\nNone,\ntitle=\"Mandatory Retirement Date\",\ndescription=(\n\"Based on the Birth Date, if it exists, it is the maximum term of\"\n\" service allowed by law.\"\n),\ncol=datetime.date,\nindex=True,\n)\ninactive_date: datetime.date | None = Field(\nNone,\ntitle=\"Date\",\ndescription=(\n\"Which date is earliest inactive date of the Justice, the retire\"\n\" date is set automatically but it is not guaranteed to to be the\"\n\" actual inactive date. So the inactive date is either that\"\n\" specified in the `end_term` or the `retire_date`, whichever is\"\n\" earlier.\"\n),\ncol=datetime.date,\nindex=True,\n)\n@validator(\"retire_date\")\ndef retire_date_70_years(cls, v, values):\nif v and values[\"birth_date\"]:\nif values[\"birth_date\"] + rd(years=MAX_JUSTICE_AGE) != v:\nraise ValueError(\"Must be 70 years from birth date.\")\nreturn v\nclass Config:\nuse_enum_values = True\n@classmethod\ndef from_data(cls, data: dict):\ndef extract_date(text: str | None) -&gt; datetime.date | None:\nreturn parse(text).date() if text else None\nbio = Bio.from_dict(data)\n# Not all have aliases; default needed\nalias = data.pop(\"Alias\", None)\nif not alias:\nif bio.last_name and bio.suffix:\nalias = f\"{bio.last_name} {bio.suffix}\".lower()\nretire_date = None\nif dob := extract_date(data.pop(\"Born\")):\nretire_date = dob + rd(years=MAX_JUSTICE_AGE)\n# Assume that the retire_date is latest possible date of inactivity\n# but if end_date is present, use this instead\ninactive_date = retire_date\nif end_date := extract_date(data.pop(\"End of term\")):\ninactive_date = end_date or retire_date\nreturn cls(\n**bio.dict(exclude_none=True),\nid=data.pop(\"#\"),\nalias=alias,\nbirth_date=dob,\nstart_term=extract_date(data.pop(\"Start of term\")),\nend_term=end_date,\nchief_date=extract_date(data.pop(\"Appointed chief\")),\nretire_date=retire_date,\ninactive_date=inactive_date,\n)\n@classmethod\ndef view_chiefs(cls, c: Connection) -&gt; list[dict]:\n\"\"\"Get general information of the chief justices and their\n        dates of appointment.\"\"\"\nview = \"chief_dates\"\nif view in c.db.view_names():\nreturn list(c.db[view].rows)\nc.db.create_view(\nview,\nsql=justice_jinja_env.get_template(\"chief_dates.sql\").render(\njustice_table=Justice.__tablename__\n),\n)\nreturn list(c.db[view].rows)\n</code></pre>"},{"location":"justice/#corpus_sc_toolkit.justice.justice_model.Justice-functions","title":"Functions","text":""},{"location":"justice/#corpus_sc_toolkit.justice.justice_model.Justice.view_chiefs","title":"<code>view_chiefs(c)</code>  <code>classmethod</code>","text":"<p>Get general information of the chief justices and their dates of appointment.</p> Source code in <code>corpus_sc_toolkit/justice/justice_model.py</code> Python<pre><code>@classmethod\ndef view_chiefs(cls, c: Connection) -&gt; list[dict]:\n\"\"\"Get general information of the chief justices and their\n    dates of appointment.\"\"\"\nview = \"chief_dates\"\nif view in c.db.view_names():\nreturn list(c.db[view].rows)\nc.db.create_view(\nview,\nsql=justice_jinja_env.get_template(\"chief_dates.sql\").render(\njustice_table=Justice.__tablename__\n),\n)\nreturn list(c.db[view].rows)\n</code></pre>"},{"location":"justice/#justice-names","title":"Justice names","text":"<p>         Bases: <code>NamedTuple</code></p> Source code in <code>corpus_sc_toolkit/justice/justice_name.py</code> Python<pre><code>class OpinionWriterName(NamedTuple):\nwriter: str | None = None\nper_curiam: bool = False\n@classmethod\ndef extract(cls, text: str | None):\nif not text:\nreturn None\nif text:\nif IS_PER_CURIAM.search(text):\nreturn cls(per_curiam=True)\nreturn cls(writer=cls.clean(text))\n@classmethod\ndef clean(cls, text: str) -&gt; str | None:\n\"\"\"Each `ponente` name stored in `decisions_tbl` of the database has been\n        made uniform, e.g.:\n        Examples:\n            &gt;&gt;&gt; OpinionWriterName.clean(\"REYES , J.B.L, Acting C.J.\") # sample name 1\n            'reyes, j.b.l.'\n            &gt;&gt;&gt; OpinionWriterName.clean(\"REYES, J, B. L. J.\") # sample name 2\n            'reyes, j.b.l.'\n        \"\"\"\nno_asterisk = re.sub(r\"\\[?(\\*)+\\]?\", \"\", text)\nsurname = init_surnames(no_asterisk)\nno_suffix = TitleSuffixClean.clean_end(surname).strip()\nrepl = CommonTypos.replace_value(no_suffix).strip()\nres = repl + \".\" if repl.endswith((\" jr\", \" sr\")) else repl\nreturn res if 4 &lt; len(res) &lt; 20 else None\n</code></pre>"},{"location":"justice/#corpus_sc_toolkit.justice.justice_name.OpinionWriterName-functions","title":"Functions","text":""},{"location":"justice/#corpus_sc_toolkit.justice.justice_name.OpinionWriterName.clean","title":"<code>clean(text)</code>  <code>classmethod</code>","text":"<p>Each <code>ponente</code> name stored in <code>decisions_tbl</code> of the database has been made uniform, e.g.:</p> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; OpinionWriterName.clean(\"REYES , J.B.L, Acting C.J.\") # sample name 1\n'reyes, j.b.l.'\n&gt;&gt;&gt; OpinionWriterName.clean(\"REYES, J, B. L. J.\") # sample name 2\n'reyes, j.b.l.'\n</code></pre> Source code in <code>corpus_sc_toolkit/justice/justice_name.py</code> Python<pre><code>@classmethod\ndef clean(cls, text: str) -&gt; str | None:\n\"\"\"Each `ponente` name stored in `decisions_tbl` of the database has been\n    made uniform, e.g.:\n    Examples:\n        &gt;&gt;&gt; OpinionWriterName.clean(\"REYES , J.B.L, Acting C.J.\") # sample name 1\n        'reyes, j.b.l.'\n        &gt;&gt;&gt; OpinionWriterName.clean(\"REYES, J, B. L. J.\") # sample name 2\n        'reyes, j.b.l.'\n    \"\"\"\nno_asterisk = re.sub(r\"\\[?(\\*)+\\]?\", \"\", text)\nsurname = init_surnames(no_asterisk)\nno_suffix = TitleSuffixClean.clean_end(surname).strip()\nrepl = CommonTypos.replace_value(no_suffix).strip()\nres = repl + \".\" if repl.endswith((\" jr\", \" sr\")) else repl\nreturn res if 4 &lt; len(res) &lt; 20 else None\n</code></pre>"},{"location":"meta/","title":"Meta","text":""},{"location":"meta/#decision-source","title":"Decision Source","text":"<p>         Bases: <code>str</code>, <code>Enum</code></p> <p>The Supreme Court website contains decisions starting from 1996 onwards. Decisions dated prior to that year are only available through various secondary sources.</p> <p>For purposes of classification and determining their provenance, we will use the following categorization:</p> source description sc 1996 onwards from the Supreme Court legacy Prior to 1996, from other sources Source code in <code>corpus_sc_toolkit/meta/source.py</code> Python<pre><code>class DecisionSource(str, Enum):\n\"\"\"The Supreme Court website contains decisions starting from 1996 onwards.\n    Decisions dated prior to that year are only available through various secondary\n    sources.\n    For purposes of classification and determining their provenance, we will use the\n    following categorization:\n    source | description\n    --:|:--\n    sc | 1996 onwards from the Supreme Court\n    legacy | Prior to 1996, from other sources\n    \"\"\"\nsc = \"sc\"\nlegacy = \"legacy\"\n</code></pre>"},{"location":"meta/#court-category","title":"Court Category","text":"<p>         Bases: <code>str</code>, <code>Enum</code></p> <p>Each Decision (which is not classified as a 'notice of a minute resolution') is categorized as being either a <code>Decision</code> or a <code>Resolution</code>.</p> <p>A minute resolution, as described by the internal rules of the Philippine Supreme Court, is characterized as follows:</p> <p>A notice of a minute resolution shall be embodied in a  letter of the Clerk of Court or the Division Clerk of Court notifying the parties of the action or actions taken in their case. In the absence of or whenever so deputized by the Clerk of Court or the Division Clerk of Court, the Assistant Clerk of Court or Assistant Division Clerk of Court may likewise sign the letter which shall be in the following form:</p> <p>x x x</p> <p>Sirs/Mesdames:</p> <p>NOTICE</p> <p>Please take notice that the Court ... x x x</p> Source code in <code>corpus_sc_toolkit/meta/category.py</code> Python<pre><code>class DecisionCategory(str, Enum):\n\"\"\"Each Decision (which is not classified as a 'notice of a minute resolution')\n    is categorized as being either a `Decision` or a `Resolution`.\n    A minute resolution, as described by the internal rules of the Philippine\n    Supreme Court, is characterized as follows:\n    &gt; A notice of a minute resolution shall be embodied in a  letter of the Clerk\n    of Court or the Division Clerk of Court notifying the parties of the action or\n    actions taken in their case. In the absence of or whenever so deputized by the\n    Clerk of Court or the Division Clerk of Court, the Assistant Clerk of Court or\n    Assistant Division Clerk of Court may likewise sign the letter which shall\n    be in the following form:\n    &gt; x x x\n    &gt; Sirs/Mesdames:\n    &gt; NOTICE\n    &gt; Please take notice that the Court ... x x x\n    \"\"\"\ndecision = \"Decision\"\nresolution = \"Resolution\"\nminute = \"Minute Resolution\"\nother = \"Unspecified\"\n@classmethod\ndef _setter(cls, text: str | None):\n\"\"\"Detect pattern based on simple matching of characters.\n        Examples:\n            &gt;&gt;&gt; text = \"R E S O L U T I O N\"\n            &gt;&gt;&gt; DecisionCategory._setter(text)\n            &lt;DecisionCategory.resolution: 'Resolution'&gt;\n            &gt;&gt;&gt; text2 = \"Decission\" # wrongly spelled\n            &gt;&gt;&gt; DecisionCategory._setter(text2)\n            &lt;DecisionCategory.decision: 'Decision'&gt;\n        \"\"\"\nif text:\nif CATEGORY_START_DECISION.search(text):\nreturn cls.decision\nelif CATEGORY_START_RESOLUTION.search(text):\nreturn cls.resolution\nreturn cls.other\n@classmethod\ndef set_category(cls, category: str | None = None, notice: int | None = 0):\nif notice:\nreturn cls.minute\nif category:\ncls._setter(category)\nreturn cls.other\n</code></pre>"},{"location":"meta/#court-composition","title":"Court Composition","text":"<p>         Bases: <code>str</code>, <code>Enum</code></p> <p>The Supreme Court may sit either <code>en banc</code> (the full 15 member complement) or by <code>division</code> (5-member groups).</p> Source code in <code>corpus_sc_toolkit/meta/composition.py</code> Python<pre><code>class CourtComposition(str, Enum):\n\"\"\"The Supreme Court may sit either `en banc` (the full 15 member complement)\n    or by `division` (5-member groups).\n    \"\"\"\nenbanc = \"En Banc\"\ndivision = \"Division\"\nother = \"Unspecified\"\n@classmethod\ndef _setter(cls, text: str | None):\n\"\"\"Detect pattern based on simple matching of characters.\n        Examples:\n            &gt;&gt;&gt; text = \"En Banc\"\n            &gt;&gt;&gt; CourtComposition._setter(text)\n            &lt;CourtComposition.enbanc: 'En Banc'&gt;\n            &gt;&gt;&gt; text2 = \"Special First Division\"\n            &gt;&gt;&gt; CourtComposition._setter(text2)\n            &lt;CourtComposition.division: 'Division'&gt;\n        \"\"\"\nif text:\nif \"banc\".casefold() in text.casefold():\nreturn cls.enbanc\nelif \"div\".casefold() in text.casefold():\nreturn cls.division\nreturn cls.other\n</code></pre>"},{"location":"meta/#citation-aspects","title":"Citation Aspects","text":""},{"location":"meta/#set-decision-id-from-values","title":"Set Decision ID from Values","text":"<p>The decision id to be used as a url slug ought to be unique, based on citation paramters if possible.</p> Source code in <code>corpus_sc_toolkit/meta/citation.py</code> Python<pre><code>def get_id_from_citation(\nfolder_name: str,\nsource: str,\ncitation: Citation,\n) -&gt; str:\n\"\"\"The decision id to be used as a url slug ought to be unique,\n    based on citation paramters if possible.\n    \"\"\"\nif not citation.slug:\nlogger.debug(f\"Citation absent: {source=}; {folder_name=}\")\nreturn folder_name\nif source == \"legacy\":\nreturn citation.slug or folder_name\nelif citation.docket:\nif report := citation.scra or citation.phil:\nreturn slugify(\"-\".join([citation.docket, report]))\nreturn slugify(citation.docket)\nreturn folder_name\n</code></pre>"},{"location":"meta/#extract-citation-from-fields","title":"Extract Citation from Fields","text":"<p>Presumes existence of the following keys:</p> <ol> <li>docket_category</li> <li>serial</li> <li>date</li> </ol> Source code in <code>corpus_sc_toolkit/meta/citation.py</code> Python<pre><code>def get_cite_from_fields(data: dict) -&gt; Citation | None:\n\"\"\"Presumes existence of the following keys:\n    1. docket_category\n    2. serial\n    3. date\n    \"\"\"\nkeys = [\"docket_category\", \"serial\", \"date\"]\nif not all([data.get(k) for k in keys]):\nreturn None\ndate_obj = parse(data[\"date\"]).date()\ndocket_partial = f\"{data['docket_category']} No. {data['serial']}\"\ndocket_str = f\"{docket_partial}, {date_obj.strftime('%b %-d, %Y')}\"\ncite = Citation.extract_citation(docket_str)\nreturn cite\n</code></pre>"},{"location":"meta/#title-tags","title":"Title Tags","text":"<p>The title of a decision is indicative of its classification. This is a sample algorithm to determine tags associated with the title.</p> <p>Parameters:</p> Name Type Description Default <code>decision_pk</code> <code>str</code> <p>The decision id</p> required <code>text</code> <code>str</code> <p>The title text</p> required <p>Yields:</p> Type Description <code>Iterator[dict[str, str]]</code> <p>Iterator[dict[str, str]]: The different tags associated based on the text.</p> Source code in <code>corpus_sc_toolkit/meta/tags.py</code> Python<pre><code>def tags_from_title(decision_pk: str, text: str) -&gt; Iterator[dict[str, str]]:\n\"\"\"The title of a decision is indicative of its classification. This is a\n    sample algorithm to determine tags associated with the title.\n    Args:\n        decision_pk (str): The decision id\n        text (str): The title text\n    Yields:\n        Iterator[dict[str, str]]: The different tags associated based on the text.\n    \"\"\"\ndef is_contained(target_text: str, matches: list[str]) -&gt; bool:\nreturn any(m.lower() in target_text.lower() for m in matches)\ntags = []\nif is_contained(\ntext,\n[\n\"habeas corpus\",\n\"guardianship of\",\n\"writ of amparo\",\n\"habeas data\",\n\"change of name\",\n\"correction of entries\",\n\"escheat\",\n],\n):\ntags.append(\"Special Proceeding\")\nif is_contained(\ntext,\n[\n\"matter of the will\",\n\"testamentary proceedings\",\n\"probate\",\n],\n):\ntags.append(\"Succession\")\nif is_contained(\ntext,\n[\n\"disbarment\",\n\"practice of law\",\n\"office of the court administrator\",\n\"disciplinary action against atty.\",\n],\n):\ntags.append(\"Legal Ethics\")\nif is_contained(\ntext,\n[\n\"for naturalization\",\n\"certificate of naturalization\",\n\"petition for naturalization\",\n\"citizen of the philippines\",\n\"commissioner of immigration\",\n\"commissioners of immigration\",\n\"philippine citizenship\",\n],\n):\ntags.append(\"Immigration\")\nif is_contained(\ntext,\n[\n\"central bank of the philippines\",\n\"bangko sentral ng pilipinas\",\n],\n):\ntags.append(\"Banking\")\nif is_contained(\ntext,\n[\n\"el pueblo de filipinas\",\n\"el pueblo de las islas filipinas\",\n\"los estados unidos\",\n\"testamentaria\",\n],\n):\ntags.append(\"Spanish\")\nif is_contained(\ntext,\n[\"the united States, plaintiff \"],\n):\ntags.append(\"United States\")\nif is_contained(\ntext,\n[\n\"people of the philipppines\",\n\"people of the philippines\",\n\"people  of the philippines\",\n\"people of the  philippines\",\n\"people of the philipines\",\n\"people of the philippine islands\",\n\"people philippines, of the\",\n\"sandiganbayan\",\n\"tanodbayan\",\n\"ombudsman\",\n],\n):\ntags.append(\"Crime\")\nif is_contained(\ntext,\n[\n\"director of lands\",\n\"land registration\",\n\"register of deeds\",\n],\n):\ntags.append(\"Property\")\nif is_contained(\ntext,\n[\n\"agrarian reform\",\n\"darab\",\n],\n):\ntags.append(\"Agrarian Reform\")\nif is_contained(\ntext,\n[\n\"collector of internal revenue\",\n\"commissioner of internal revenue\",\n\"bureau of internal revenue\",\n\"court of tax appeals\",\n],\n):\ntags.append(\"Taxation\")\nif is_contained(\ntext,\n[\n\"collector of customs\",\n\"commissioner of customs\",\n],\n):\ntags.append(\"Customs\")\nif is_contained(\ntext,\n[\n\"commission on elections\",\n\"comelec\",\n\"electoral tribunal\",\n],\n):\ntags.append(\"Elections\")\nif is_contained(\ntext,\n[\n\"workmen's compensation commission\",\n\"employees' compensation commission\",\n\"national labor relations commission\",\n\"bureau of labor relations\",\n\"nlrc\",\n\"labor union\",\n\"court of industrial relations\",\n],\n):\ntags.append(\"Labor\")\nfor tag in tags:\nyield {\"decision_id\": decision_pk, \"tag\": tag}\n</code></pre>"},{"location":"meta/#vote-lines","title":"Vote Lines","text":""},{"location":"meta/#clean","title":"Clean","text":"<p>Various steps to remove non-essential text from the voteline found.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str | None</code> <p>The voteline.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: The cleaned voteline, if found.</p> Source code in <code>corpus_sc_toolkit/meta/voteline.py</code> Python<pre><code>def voteline_clean(text: str | None) -&gt; str | None:\n\"\"\"Various steps to remove non-essential text from the voteline found.\n    Args:\n        text (str | None): The voteline.\n    Returns:\n        str | None: The cleaned voteline, if found.\n    \"\"\"\nif not text:\nreturn None\ntext = text.lstrip(\". \").rstrip()\ninit = markdownify(text).replace(\"*\", \"\").strip()\nif len(text) &lt; VOTEFULL_MIN_LENGTH:\nreturn None\nclean = WHITELIST.sub(\"\", init)\nadd_concur_line = clean.replace(\"concur.\", \"concur.\\n\")\nunchair = CHAIRPERSON.sub(\"\", add_concur_line)\nrelined = multilines.sub(\"\\n\", unchair)\nstartings = startlines.sub(\"\", relined)\nendings = endlines.sub(\"\", startings)\nreturn endings.strip()\n</code></pre>"},{"location":"meta/#validate","title":"Validate","text":"<p>Checks if certain criteria would qualify the line as a voteline.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Candidate text.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the text can be considered a voteline.</p> Source code in <code>corpus_sc_toolkit/meta/voteline.py</code> Python<pre><code>def is_line_ok(text: str) -&gt; bool:\n\"\"\"Checks if certain criteria would qualify the line as a voteline.\n    Args:\n        text (str): Candidate text.\n    Returns:\n        bool: Whether the text can be considered a voteline.\n    \"\"\"\nhas_proper_length = VOTELINE_MAX_LENGTH &gt; len(text) &gt; VOTELINE_MIN_LENGTH\nhas_indicator = re.search(r\"(C\\.|J\\.)?J\\.\", text)\nnot_all_caps = not text.isupper()\nfirst_char_capital_letter = re.search(r\"^[A-Z]\", text)\nreturn all(\n[\nhas_proper_length,\nhas_indicator,\nnot_all_caps,\nfirst_char_capital_letter,\n]\n)\n</code></pre>"},{"location":"meta/#extract","title":"Extract","text":"<p>Applicable to content found in the elibrary, this refers to a line under the decision / resolution which consolidates the votes of each member of the Court.</p> <p>Parameters:</p> Name Type Description Default <code>decision_pk</code> <code>str</code> <p>The decision id</p> required <code>text</code> <code>str</code> <p>The title text</p> required <p>Yields:</p> Type Description <code>Iterator[dict[str, str]]</code> <p>Iterator[dict[str, str]]: The voting lines associated with the decision id.</p> Source code in <code>corpus_sc_toolkit/meta/voteline.py</code> Python<pre><code>def extract_votelines(decision_pk: str, text: str) -&gt; Iterator[dict[str, str]]:\n\"\"\"Applicable to content found in the elibrary, this refers to a line\n    under the decision / resolution which consolidates the votes of each\n    member of the Court.\n    Args:\n        decision_pk (str): The decision id\n        text (str): The title text\n    Yields:\n        Iterator[dict[str, str]]: The voting lines associated with the decision id.\n    \"\"\"\nfor line in text.splitlines():\nif is_line_ok(line):\nyield dict(decision_id=decision_pk, text=line)\n</code></pre>"},{"location":"notes/","title":"Notes","text":"Python<pre><code>&gt;&gt;&gt; from corpus_base.helpers import most_popular\n&gt;&gt;&gt; [i for i in most_popular(c, db)] # excluding per curiams and unidentified cases\n[\n('1994-07-04', '2017-08-09', 'mendoza', 1297), # note multiple personalities named mendoza, hence long range from 1994-2017\n('1921-10-22', '1992-07-03', 'paras', 1287), # note multiple personalities named paras, hence long range from 1921-1992\n('2009-03-17', '2021-03-24', 'peralta', 1243),\n('1998-06-18', '2009-10-30', 'quisumbing', 1187),\n('1999-06-28', '2011-06-02', 'ynares-santiago', 1184),\n('1956-04-28', '2008-04-04', 'panganiban', 1102),\n('1936-11-19', '2009-11-05', 'concepcion', 1058), # note multiple personalities named concepcion, hence long range from 1936-2009\n('1954-07-30', '1972-08-18', 'reyes, j.b.l.', 1053),\n('1903-11-21', '1932-03-31', 'johnson', 1043),\n('1950-11-16', '1999-05-23', 'bautista angelo', 1028), # this looks like bad data\n('2001-11-20', '2019-10-15', 'carpio', 1011),\n...\n]\n</code></pre>"},{"location":"notes/#view-chief-justice-dates","title":"View chief justice dates","text":"Python<pre><code>&gt;&gt;&gt; from corpus_base import Justice\n&gt;&gt;&gt; Justice.view_chiefs(c)\n[\n{\n'id': 178,\n'last_name': 'Gesmundo',\n'chief_date': '2021-04-05',\n'max_end_chief_date': None,\n'actual_inactive_as_chief': None,\n'years_as_chief': None\n},\n{\n'id': 162,\n'last_name': 'Peralta',\n'chief_date': '2019-10-23',\n'max_end_chief_date': '2021-04-04',\n'actual_inactive_as_chief': '2021-03-27',\n'years_as_chief': 2\n},\n{\n'id': 163,\n'last_name': 'Bersamin',\n'chief_date': '2018-11-26',\n'max_end_chief_date': '2019-10-22',\n'actual_inactive_as_chief': '2019-10-18',\n'years_as_chief': 1\n},\n{\n'id': 160,\n'last_name': 'Leonardo-De Castro',\n'chief_date': '2018-08-28',\n'max_end_chief_date': '2018-11-25',\n'actual_inactive_as_chief': '2018-10-08',\n'years_as_chief': 0\n}...\n]\n</code></pre>"},{"location":"loader/path/","title":"Decision Loaded from Path","text":""},{"location":"loader/path/#contents-of-row-from-path","title":"Contents of Row From Path","text":"<p>The fields that are created through this function will ultimately map out to a DecisionRow instance, a third-party library.</p> <p>It consolidates the various metadata from the toolkit.</p> <p>It assumes that a decision will be loaded from a <code>details.yaml</code> file with the following directory structure:</p> Bash<pre><code>\u251c\u2500\u2500 /decisions\n\u2502   \u251c\u2500\u2500 /sc # from the supreme court e-library\n\u2502   \u2502   \u251c\u2500\u2500 /folder_name, e.g. 12341 # the original id when scraped\n\u2502   \u2502       \u251c\u2500\u2500 /details.yaml # the file containing the metadata that is `p`\n\u2502   \u251c\u2500\u2500 /legacy\n\u2502   \u2502   \u251c\u2500\u2500 /folder_name, e.g. legacy-idfs2 # the original id when scraped\n</code></pre> <p>The path <code>p</code> will have the following properties:</p> <ol> <li><code>parent.name</code> = name of the parent folder, e.g. 12341 or legacy-idfs2 above</li> <li><code>p.parent.parent.stem</code> = name of the grandparent folder, e.g. sc or legacy</li> </ol> <p>The properties will be combined with the <code>citation</code> extracted from the the data to form a unique slug:</p> <p>In terms of what's found in the <code>/folder_name</code>, the directory may contain some html files, e.g.:</p> <ol> <li><code>fallo.html</code></li> <li><code>ponencia.html</code></li> <li><code>annex.html</code></li> </ol> <p>These may be utilized later in DecisionHTMLConvertMarkdown</p> <p>The database <code>db</code> is relevant for purposes of determining the correct justice to include as the ponente of the decision.</p> Source code in <code>corpus_sc_toolkit/loader/from_path.py</code> Python<pre><code>def decision_from_path(p: Path, db: Database) -&gt; dict:\n\"\"\"The fields that are created through this function will ultimately\n    map out to a DecisionRow instance, a third-party library.\n    It consolidates the various [metadata][meta] from the toolkit.\n    It assumes that a decision will be loaded from a `details.yaml` file\n    with the following directory structure:\n    ```sh\n    \u251c\u2500\u2500 /decisions\n    \u2502   \u251c\u2500\u2500 /sc # from the supreme court e-library\n    \u2502   \u2502   \u251c\u2500\u2500 /folder_name, e.g. 12341 # the original id when scraped\n    \u2502   \u2502       \u251c\u2500\u2500 /details.yaml # the file containing the metadata that is `p`\n    \u2502   \u251c\u2500\u2500 /legacy\n    \u2502   \u2502   \u251c\u2500\u2500 /folder_name, e.g. legacy-idfs2 # the original id when scraped\n    ```\n    The path `p` will have the following properties:\n    1. `parent.name` = name of the parent folder, e.g. _12341_ or _legacy-idfs2_ above\n    2. `p.parent.parent.stem` = name of the grandparent folder, e.g. _sc_ or _legacy_\n    The properties will be combined with the `citation` extracted from the\n    the data to form a [unique slug][set-decision-id-from-values]:\n    In terms of what's found in the `/folder_name`, the directory may contain some\n    html files, e.g.:\n    1. `fallo.html`\n    2. `ponencia.html`\n    3. `annex.html`\n    These may be utilized later in [DecisionHTMLConvertMarkdown][combine-html-files-of-e-lib-ponencia-to-markdown]\n    The database `db` is relevant for purposes of determining the correct\n    [justice][justice] to include as the ponente of the decision.\n    \"\"\"  # noqa: E501\nf = p.parent / \"fallo.html\"\ndata = yaml.safe_load(p.read_text())\ncite = Citation.extract_citation_from_data(data)\nid = get_id_from_citation(\nfolder_name=p.parent.name,\nsource=p.parent.parent.stem,\ncitation=cite,\n)\nponencia_fields = CandidateJustice(\ndb=db,\ntext=data.get(\"ponente\"),\ndate_str=data.get(\"date_prom\"),\n).ponencia\nreturn dict(\nid=id,\norigin=p.parent.name,\nsource=DecisionSource(p.parent.parent.stem),\nis_pdf=False,\ncreated=p.stat().st_ctime,\nmodified=p.stat().st_mtime,\ntitle=data.get(\"case_title\"),\ndescription=cite.display,\ndate=data.get(\"date_prom\"),\ncomposition=CourtComposition._setter(data.get(\"composition\")),\ncategory=DecisionCategory._setter(data.get(\"category\")),\nfallo=markdownify(f.read_text()) if f.exists() else None,\nvoting=voteline_clean(data.get(\"voting\")),\ncitation=cite,\nemails=data.get(\"emails\", [\"bot@lawsql.com\"]),\n**ponencia_fields,\n)\n</code></pre>"},{"location":"loader/path/#ponencia-markdown","title":"Ponencia Markdown","text":""},{"location":"loader/path/#combine-html-files-of-e-lib-ponencia-to-markdown","title":"Combine html files of e-lib ponencia to markdown","text":"<p>Presumes the existence of various html files to construct a markdown document.</p> <p>Requires a <code>folder</code> which contains:</p> <ol> <li><code>ponencia.html</code></li> <li><code>fallo.html</code></li> <li><code>annex.html</code></li> </ol> Source code in <code>corpus_sc_toolkit/loader/txt/converter.py</code> Python<pre><code>@dataclass\nclass DecisionHTMLConvertMarkdown:\n\"\"\"Presumes the existence of various html files to construct a markdown document.\n    Requires a `folder` which contains:\n    1. `ponencia.html`\n    2. `fallo.html`\n    3. `annex.html`\n    \"\"\"\nfolder: Path\n@property\ndef result(self):\n\"\"\"Add a header on top of the text, then supply the body of the ponencia,\n        followed by the fallo and the annex of footnotes.\"\"\"\ntxt = \"# Ponencia\\n\\n\"\nif base := self.convert_html_content(\"ponencia.html\"):\ntxt += f\"{base.strip()}\"\nif fallo := self.convert_html_content(\"fallo.html\"):\ntxt += f\"\\n\\n{fallo.strip()}\"\nif annex := self.convert_html_content(\"annex.html\"):\nannex_footnoted = MD_FOOTNOTE_AFTER_LEFT_RIGHT.sub(\": \", annex)\ntxt += f\"\\n\\n{annex_footnoted.strip()}\"\nreturn txt.strip()\ndef convert_html_content(self, htmlfilename: str) -&gt; str | None:\np = self.folder / f\"{htmlfilename}\"\nif p.exists():\nhtml_content = p.read_text()\nmd_content = self.from_html_to_md(html_content)\nreturn md_content\nreturn None\ndef revise_md_footnotes(self, raw: str):\npartial = MD_FOOTNOTE_LEFT.sub(\"[^\", raw)\nreplaced = MD_FOOTNOTE_RIGHT_POST_LEFT.sub(\"]\", partial)\nreturn replaced\ndef from_html_to_md(self, raw: str) -&gt; str:\noptions = dict(\nsup_symbol=\"^\",  # footnote pattern which will be replaced\nescape_asterisks=False,\nescape_underscores=False,\n)\ninitial_pass = markdownify(raw, **options)\nrevised_pass = self.revise_md_footnotes(initial_pass)\nreturn revised_pass\n</code></pre>"},{"location":"loader/path/#corpus_sc_toolkit.loader.txt.converter.DecisionHTMLConvertMarkdown-attributes","title":"Attributes","text":""},{"location":"loader/path/#corpus_sc_toolkit.loader.txt.converter.DecisionHTMLConvertMarkdown.result","title":"<code>result</code>  <code>property</code>","text":"<p>Add a header on top of the text, then supply the body of the ponencia, followed by the fallo and the annex of footnotes.</p>"},{"location":"loader/path/#create-a-markdown-file-in-the-target-folder","title":"Create a markdown file in the target folder","text":"Source code in <code>corpus_sc_toolkit/loader/txt/converter.py</code> Python<pre><code>def add_markdown_file(p: Path, text: str):\nopinions_path = p / \"opinions\"\nopinions_path.mkdir(exist_ok=True)\nponencia_path = opinions_path / \"ponencia.md\"\n# if not ponencia_path.exists():\nponencia_path.write_text(text)\n</code></pre>"},{"location":"loader/pdf/","title":"Decision Loaded from PDF","text":""},{"location":"loader/pdf/#source-of-extraction","title":"Source of Extraction","text":"<p>There is a pre-existing sqlite database that is replicated via litestream to the repository. This database, found in <code>s3://corpus-pdf/db</code> refers to content previously extracted from pdf files.</p> Python<pre><code>&gt;&gt;&gt; from pylts import ConfigS3\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from sqlpyd import Connection\n&gt;&gt;&gt; stream = ConfigS3(s3='s3://corpus-pdf/db', folder=Path().cwd() / \"data\")\n# stream.restore()\n&gt;&gt;&gt; c = Connection(DatabasePath=str(stream.dbpath), WAL=True) # database access\n&gt;&gt;&gt; c.db # An sqlite-utils Database instance\n</code></pre>"},{"location":"loader/pdf/#means-of-generating-rows","title":"Means of Generating Rows","text":"Python<pre><code>&gt;&gt;&gt; from corpus_sc_toolkit import InterimDecision\n&gt;&gt;&gt; res = InterimDecision.limited_decisions(c.db)\n&gt;&gt;&gt; x = next(res) # x is an instance of InterimDecision\n</code></pre>"},{"location":"loader/pdf/#contents-of-row-from-path","title":"Contents of Row from Path","text":"<p>An <code>Interim Decision</code>'s fields will ultimately map out to a DecisionRow instance, a third-party library.</p> <p>The <code>row</code> described here is based on an sql exression:</p> SQL<pre><code>WITH opinions_included AS (\nSELECT\nop.id,\nop.pdf,\nop.title,\nop_meta.writer,\nop_meta.body opinion_body,\nop_meta.annex opinion_annex\nFROM\npre_tbl_opinions op\nJOIN pre_tbl_opinion_meta op_meta\nON op_meta.opinion_id = op.id\nWHERE\nop.category = caso.category\nAND op.serial = caso.serial\nAND op.date = caso.date\n),\nopinion_list_data AS (\nSELECT\njson_group_array(\njson_object(\n'id',\nop_inc.id,\n'pdf',\nop_inc.pdf,\n'title',\nop_inc.title,\n'writer',\nop_inc.writer,\n'body',\nop_inc.opinion_body,\n'annex',\nop_inc.opinion_annex\n)\n) opinion_list\nFROM\nopinions_included op_inc\n),\nopinions_with_ponencia AS (\nSELECT\njson_insert(\n(\nSELECT\nopinion_list\nFROM\nopinion_list_data\n),\n'$[#]',\njson_object(\n'id',\ncaso.id,\n'pdf',\ncaso.pdf,\n'title',\nCASE meta.notice\nWHEN 1 THEN 'Notice'\nWHEN 0 THEN 'Ponencia'\nEND,\n'writer',\nmeta.writer,\n'body',\nmeta.body,\n'annex',\nmeta.annex\n)\n) opinions\n)\nSELECT\ncaso.scraped,\ncaso.id,\ncaso.title,\ncaso.category docket_category,\ncaso.serial,\ncaso.date,\ncaso.pdf,\nmeta.composition,\nmeta.notice,\nmeta.category,\n(\nSELECT\nopinions\nFROM\nopinions_with_ponencia\n) opinions\nFROM\npre_tbl_decisions caso\nJOIN pre_tbl_decision_meta meta\nON meta.decision_id = caso.id\nWHERE\nmeta.notice = 0\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>Database</code> <p>sqlite_utils.db wrapper over sqlite3</p> required <code>row</code> <code>dict[str, Any]</code> <p>A matching row based on the sql expression above</p> required <p>Returns:</p> Type Description <code>InterimDecision | None</code> <p>InterimDecision | None: If relevant fields are present, produce an instance of an InterimDecision</p> Source code in <code>corpus_sc_toolkit/loader/from_pdf.py</code> Python<pre><code>def decision_from_pdf_db(\ndb: Database, row: dict[str, Any]\n) -&gt; InterimDecision | None:\n\"\"\"An `Interim Decision`'s fields will ultimately\n    map out to a DecisionRow instance, a third-party library.\n    The `row` described here is based on an sql exression:\n    ```sql\n    WITH opinions_included AS (\n    SELECT\n        op.id,\n        op.pdf,\n        op.title,\n        op_meta.writer,\n        op_meta.body opinion_body,\n        op_meta.annex opinion_annex\n    FROM\n        pre_tbl_opinions op\n        JOIN pre_tbl_opinion_meta op_meta\n        ON op_meta.opinion_id = op.id\n    WHERE\n        op.category = caso.category\n        AND op.serial = caso.serial\n        AND op.date = caso.date\n    ),\n    opinion_list_data AS (\n    SELECT\n        json_group_array(\n        json_object(\n            'id',\n            op_inc.id,\n            'pdf',\n            op_inc.pdf,\n            'title',\n            op_inc.title,\n            'writer',\n            op_inc.writer,\n            'body',\n            op_inc.opinion_body,\n            'annex',\n            op_inc.opinion_annex\n        )\n        ) opinion_list\n    FROM\n        opinions_included op_inc\n    ),\n    opinions_with_ponencia AS (\n    SELECT\n        json_insert(\n        (\n            SELECT\n            opinion_list\n            FROM\n            opinion_list_data\n        ),\n        '$[#]',\n        json_object(\n            'id',\n            caso.id,\n            'pdf',\n            caso.pdf,\n            'title',\n            CASE meta.notice\n            WHEN 1 THEN 'Notice'\n            WHEN 0 THEN 'Ponencia'\n            END,\n            'writer',\n            meta.writer,\n            'body',\n            meta.body,\n            'annex',\n            meta.annex\n        )\n        ) opinions\n    )\n    SELECT\n    caso.scraped,\n    caso.id,\n    caso.title,\n    caso.category docket_category,\n    caso.serial,\n    caso.date,\n    caso.pdf,\n    meta.composition,\n    meta.notice,\n    meta.category,\n    (\n        SELECT\n        opinions\n        FROM\n        opinions_with_ponencia\n    ) opinions\n    FROM\n        pre_tbl_decisions caso\n        JOIN pre_tbl_decision_meta meta\n        ON meta.decision_id = caso.id\n    WHERE\n        meta.notice = 0\n    ```\n    Args:\n        db (Database): sqlite_utils.db wrapper over sqlite3\n        row (dict[str, Any]): A matching row based on the sql expression above\n    Returns:\n        InterimDecision | None: If relevant fields are present, produce an instance of\n            an InterimDecision\n    \"\"\"\nif not (cite := get_cite_from_fields(row)):\nlogger.error(f\"Bad citation in {row['id']=}\")\nreturn None\nopx = InterimOpinion.setup(db, row)\nif not opx or not opx.get(\"opinions\"):\nlogger.error(f\"No opinions detected in {row['id']=}\")\nreturn None\nid = get_id_from_citation(\nfolder_name=row[\"id\"],\nsource=DecisionSource.sc.value,\ncitation=cite,\n)\ncat = DecisionCategory.set_category(\ncategory=row.get(\"category\"),\nnotice=row.get(\"notice\"),\n)\nreturn InterimDecision(\nid=id,\norigin=f\"{SC_BASE_URL}/{row['id']}\",\ncase_title=row[\"title\"],\ndate_prom=parse(row[\"date\"]).date(),\ndate_scraped=parse(row[\"scraped\"]).date(),\ncitation=cite,\ncomposition=CourtComposition._setter(text=row[\"composition\"]),\ncategory=cat,\nopinions=opx[\"opinions\"],\nraw_ponente=opx.get(\"raw_ponente\", None),\nper_curiam=opx.get(\"per_curiam\", False),\njustice_id=opx.get(\"justice_id\", None),\n)\n</code></pre>"}]}